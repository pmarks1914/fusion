{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba78e9ed-ea3f-49e0-92bb-80516982cbc0",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '3_without_sift_algo_zscore_on_svm_classifier_jaffe.joblib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 173>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28mprint\u001b[39m(ground_truth_labels, predicted_labels)\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# Test the recognition rate on the test dataset\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# test_recognition_rate(\"./ckdvalidate\")\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m \u001b[43mtest_recognition_rate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../jaffedvalidate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36mtest_recognition_rate\u001b[0;34m(test_directory)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtest_recognition_rate\u001b[39m(test_directory):\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;66;03m# Load the trained SVM classifier\u001b[39;00m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;66;03m# classifier = joblib.load(\"3_without_orb_algo_zscore_on_ck_svm_classifier_ck.joblib\")\u001b[39;00m\n\u001b[0;32m--> 118\u001b[0m     classifier \u001b[38;5;241m=\u001b[39m \u001b[43mjoblib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m3_without_sift_algo_zscore_on_svm_classifier_jaffe.joblib\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;66;03m# Initialize lists to store predicted labels and ground truth labels\u001b[39;00m\n\u001b[1;32m    120\u001b[0m     predicted_labels \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/joblib/numpy_pickle.py:650\u001b[0m, in \u001b[0;36mload\u001b[0;34m(filename, mmap_mode)\u001b[0m\n\u001b[1;32m    648\u001b[0m         obj \u001b[38;5;241m=\u001b[39m _unpickle(fobj)\n\u001b[1;32m    649\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 650\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    651\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m _read_fileobject(f, filename, mmap_mode) \u001b[38;5;28;01mas\u001b[39;00m fobj:\n\u001b[1;32m    652\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fobj, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    653\u001b[0m                 \u001b[38;5;66;03m# if the returned file object is a string, this means we\u001b[39;00m\n\u001b[1;32m    654\u001b[0m                 \u001b[38;5;66;03m# try to load a pickle file generated with an version of\u001b[39;00m\n\u001b[1;32m    655\u001b[0m                 \u001b[38;5;66;03m# Joblib so we load it with joblib compatibility function.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '3_without_sift_algo_zscore_on_svm_classifier_jaffe.joblib'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from operator import le\n",
    "import cv2\n",
    "import dlib\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from imutils import face_utils\n",
    "from skimage.feature import hog, local_binary_pattern\n",
    "import mahotas as mh\n",
    "import joblib\n",
    "from sklearn import svm\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import imgaug.augmenters as iaa\n",
    "\n",
    "# Resize descriptors to a consistent length\n",
    "desired_length = 1000\n",
    "# Initialize the label variable\n",
    "img_label = []\n",
    "feature_descriptors_fused = []\n",
    "\n",
    "\n",
    "def file_looper_transformer_extract_features_and_train():\n",
    "    source_data_label = \"\"\n",
    "    augmentation_seq = iaa.Sequential([\n",
    "        # iaa.Affine(rotate=(0, 10)),  # Rotate images by -10 to +10 degrees\n",
    "        iaa.Multiply((0.8, 1.0)),  # Multiply pixel values by a factor between 0.8 and 1.2\n",
    "        # iaa.GammaContrast(gamma=(0.8, 1.2)),  # Adjust gamma contrast between 0.8 and 1.2\n",
    "        # iaa.ElasticTransformation(alpha=50, sigma=5)  # Apply elastic transformations\n",
    "        # iaa.Fliplr(),  # Flip images horizontally with a 50% chance\n",
    "        # iaa.Multiply((0.8, 1.2)),  # Multiply pixel values by a factor between 0.8 and 1.2\n",
    "        # iaa.GammaContrast(),  # Adjust gamma contrast between 0.8 and 1.2\n",
    "        # iaa.ElasticTransformation(alpha=50, sigma=5)  # Apply elastic transformations\n",
    "        # iaa.Affine(rotate=(0, 10)),  # Rotate images by -10 to +10 degrees\n",
    "        # iaa.GaussianBlur(sigma=(0, 1.0)),  # Apply Gaussian blur with a sigma between 0 and 1.0\n",
    "        # iaa.AdditiveGaussianNoise(scale=(0, 0.05*255)),  # Add Gaussian noise with a scale of 0 to 0.05*255\n",
    "    ])\n",
    "    for dirname, _, filenames in os.walk('./cktrain'):\n",
    "        for filename in filenames:\n",
    "            # print(os.path.join(dirname, filename))\n",
    "            img_name, img_extention = os.path.splitext(filename)\n",
    "            expression_label = (os.path.join(dirname, filename)).split(os.sep)[2]\n",
    "            if source_data_label == '':\n",
    "                source_data_label = (os.path.join(dirname, filename)).split(os.sep)[1]\n",
    "\n",
    "            if(img_extention == \".jpg\" or img_extention == \".png\"):\n",
    "                image = cv2.imread(os.path.join(dirname, filename))\n",
    "                # Apply data augmentation\n",
    "                image = augmentation_seq(image=image)\n",
    "                \n",
    "                ext_feature, the_label = face_detection_extraction(image, expression_label)\n",
    "                feature_descriptors_fused.append(ext_feature)\n",
    "                img_label.append(expression_label)\n",
    "\n",
    "\n",
    "    # return feature_descriptors_fused, img_label\n",
    "    svmc(feature_descriptors_fused, img_label, source_data_label)\n",
    "\n",
    "\n",
    "def face_detection_extraction(image, image_label):\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = detector(gray, 1)\n",
    "    feature_list = []  # List to store the extracted features\n",
    "    label_list = []  # List to store the corresponding labels\n",
    "\n",
    "    for face in faces:\n",
    "        landmarks = predictor(gray, face)\n",
    "        x, y, w, h = face.left(), face.top(), face.width(), face.height()\n",
    "        extracted_face = image[y:y+h, x:x+w]\n",
    "        extracted_face = np.array(extracted_face)\n",
    "\n",
    "        shape = face_utils.shape_to_np(landmarks)\n",
    "        # Draw on our image, all the found 68 coordinate points (x,y)\n",
    "        for (x, y) in shape:\n",
    "            cv2.circle(image, (x, y), 2, (0, 255, 0), -1)\n",
    "        weight1 = 0.9  # Weight for descriptors lbp\n",
    "        weight2 = 0.9  # Weight for descriptors hog\n",
    "        weight3 = 0.2  # Weight for descriptors orb\n",
    "        weight4 = 0.2  # Weight for descriptors sift\n",
    "            \n",
    "        hog_descriptors = hog_extraction(extracted_face)\n",
    "        try:  \n",
    "            # Calculate the Z-scores for each descriptor\n",
    "            zscore_hog_descriptors = (hog_descriptors - np.mean(hog_descriptors)) / np.std(hog_descriptors)\n",
    "            # Fusion using weighted sum\n",
    "            hog_descriptors = weight2 * zscore_hog_descriptors   \n",
    "        except Exception as e:\n",
    "            # print(str(e), np.std(hog_descriptors))\n",
    "            pass    \n",
    "        hog_descriptors = np.resize(hog_descriptors, (desired_length,))\n",
    "\n",
    "        lbp_descriptors = lbp_extraction(extracted_face)\n",
    "        # Calculate the Z-scores for each descriptor\n",
    "        zscore_lbp_descriptors = (lbp_descriptors - np.mean(lbp_descriptors)) / np.std(lbp_descriptors)\n",
    "        # Fusion using weighted sum\n",
    "        lbp_descriptors = weight1 * zscore_lbp_descriptors \n",
    "        lbp_descriptors = np.resize(lbp_descriptors, (desired_length,))\n",
    "\n",
    "        orb_descriptors = orb_extraction(extracted_face)\n",
    "        # Calculate the Z-scores for each descriptor\n",
    "        # print(\" >>>\", np.std(orb_descriptors))\n",
    "        # print(\" <  > \", orb_descriptors - np.mean(orb_descriptors) )\n",
    "        try:\n",
    "            zscore_orb_descriptors = (orb_descriptors - np.mean(orb_descriptors)) / np.std(orb_descriptors)\n",
    "            # Fusion using weighted sum\n",
    "            orb_descriptors = weight3 * zscore_orb_descriptors \n",
    "            # print(\"orb_descriptors \", orb_descriptors)\n",
    "        except Exception as e:\n",
    "            # print(str(e))\n",
    "            pass\n",
    "        orb_descriptors = np.resize(orb_descriptors, (desired_length,))\n",
    "\n",
    "        sift_descriptors = sift_extraction(extracted_face)\n",
    "        try:\n",
    "            # Calculate the Z-scores for each descriptor\n",
    "            zscore_sift_descriptors = (sift_descriptors - np.mean(sift_descriptors)) / np.std(sift_descriptors)\n",
    "            # Fusion using weighted sum\n",
    "            sift_descriptors = weight4 * zscore_sift_descriptors   \n",
    "        except Exception as e:\n",
    "            # print(str(e))\n",
    "            pass    \n",
    "        sift_descriptors = np.resize(sift_descriptors, (desired_length,))\n",
    "\n",
    "        # fused_features = lbp_descriptors + hog_descriptors + sift_descriptors\n",
    "        fused_features = hog_descriptors\n",
    "        if lbp_descriptors is not None:\n",
    "            fused_features += lbp_descriptors\n",
    "        if sift_descriptors is not None:\n",
    "            fused_features += sift_descriptors.astype(np.float64)\n",
    "\n",
    "        # fused_features = np.concatenate((hog_descriptors, lbp_descriptors, sift_descriptors))\n",
    "\n",
    "        if len(fused_features) > 0:\n",
    "            feature_list.append(fused_features)\n",
    "            label_list.append(image_label)  # Add the label to the list\n",
    "\n",
    "    return feature_list, label_list\n",
    "\n",
    "        # print(fused_features)\n",
    "        \n",
    "        # Display the extracted faces\n",
    "        # cv2.imshow(\"Landmark localization\", extracted_face)\n",
    "        # plt.imshow(pixels)\n",
    "        # plt.axis('off')\n",
    "        # plt.show()\n",
    "\n",
    "def hog_extraction(extracted_face):\n",
    "    # Convert the image to grayscale\n",
    "    image_gray = cv2.cvtColor(extracted_face, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Define HOG parameters\n",
    "    orientations = 9  # Number of gradient orientations\n",
    "    pixels_per_cell = (8, 8)  # Cell size in pixels\n",
    "    cells_per_block = (2, 2)  # Number of cells in each block\n",
    "\n",
    "    # Compute HOG features\n",
    "    hog_image, hog_features = hog(image_gray, orientations=orientations, pixels_per_cell=pixels_per_cell, cells_per_block=cells_per_block, visualize=True)    \n",
    "    # print(hog_features)\n",
    "    disply_feature(\"HOG\", hog_features)\n",
    "    return hog_features\n",
    "\n",
    "def lbp_extraction(extracted_face):\n",
    "    # Compute LBP features\n",
    "\n",
    "    # Get the dimensions of the image\n",
    "    # height, width, channels = extracted_face.shape\n",
    "\n",
    "    # Compute LBP features\n",
    "    radius = 3\n",
    "    n_points = 8 * radius\n",
    "    # convert to 2 dimentional\n",
    "    extracted_face = cv2.cvtColor(extracted_face, cv2.COLOR_BGR2GRAY)\n",
    "    lbp_features = local_binary_pattern(extracted_face, n_points, radius, method='default')\n",
    "    # print(lbp_features)\n",
    "    disply_feature(\"LBP\", lbp_features)\n",
    "    return lbp_features\n",
    "\n",
    "# Scale-Invariant Feature Transform descriptor\n",
    "def sift_extraction(extracted_face):\n",
    "    # Create a SIFT object\n",
    "    sift = cv2.SIFT_create()\n",
    "    # Detect keypoints and compute descriptors\n",
    "    keypoints, descriptors = sift.detectAndCompute(extracted_face, None)\n",
    "    # Draw keypoints on the image\n",
    "    image_with_keypoints = cv2.drawKeypoints(extracted_face, keypoints, None)\n",
    "    # print(descriptors)\n",
    "    disply_feature(\"SIFT\", image_with_keypoints)\n",
    "    return descriptors\n",
    "\n",
    "def orb_extraction(extracted_face):\n",
    "    # Create an ORB object with custom parameters\n",
    "    orb = cv2.ORB_create(nfeatures=1000, scaleFactor=1.2, nlevels=8, edgeThreshold=15)\n",
    "    # Resize the extracted face to a larger size for better feature extraction\n",
    "    extracted_face = cv2.resize(extracted_face, (250, 250))\n",
    "    # Convert the face image to grayscale\n",
    "    extracted_face = cv2.cvtColor(extracted_face, cv2.COLOR_BGR2GRAY)\n",
    "    # Detect keypoints and compute descriptors\n",
    "    keypoints, descriptors = orb.detectAndCompute(extracted_face, None)\n",
    "    # Draw keypoints on the image\n",
    "    image_with_keypoints = cv2.drawKeypoints(extracted_face, keypoints, None, (0, 255, 0), cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "    # disply_feature(\"ORB\", image_with_keypoints)\n",
    "    return descriptors\n",
    "\n",
    "def disply_feature(features_type, features):\n",
    "    # cv2.imshow(features_type, features)\n",
    "    # # plt.imshow( features)\n",
    "    # plt.axis('off')\n",
    "    # plt.show()\n",
    "    pass\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "def svmc(fused_features, img_labels, source_data_label):\n",
    "    \n",
    "    # Create arrays to store the features and labels\n",
    "    fused_features = np.array(fused_features)\n",
    "    img_labels = np.array(img_labels)\n",
    "    \n",
    "    # Reshape the fused features to have two dimensions\n",
    "    # fused_features = fused_features.reshape(-1, fused_features.shape[2])\n",
    "    fused_features = fused_features.reshape(fused_features.shape[0], -1)\n",
    " \n",
    "    # Normalize the feature vectors\n",
    "    scaler = StandardScaler()\n",
    "    fused_features = scaler.fit_transform(fused_features)\n",
    "\n",
    "    # Handle missing values with an imputer transformer\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    fused_features = imputer.fit_transform(fused_features)\n",
    "\n",
    "    # Split the fused features data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(fused_features, img_labels, test_size=0.1412, random_state=44)\n",
    "\n",
    "    # Create an SVM classifier\n",
    "    # instantiate classifier with linear kernel and C=100\n",
    "    svc = svm.SVC(kernel='linear', C=100)\n",
    "\n",
    "    # Train the classifier\n",
    "    svc.fit(X_train, y_train)\n",
    "\n",
    "    # Predict labels for the test set\n",
    "    y_pred = svc.predict(X_test)\n",
    "    # print(y_pred)\n",
    "    # print(\"< ---------------- >\")\n",
    "    # print(y_test)\n",
    "    # print(\"< ---------------- >\")\n",
    "    # print(X_train)\n",
    "    # print(\"< ---------------- >\")\n",
    "    # print(X_test)\n",
    "\n",
    "    # Evaluate the classifier's performance\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='macro', zero_division=1)\n",
    "    recall = recall_score(y_test, y_pred, average='macro', zero_division=1)\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    print(\" si_3_without_orb_algo_zscore_on_ck_svm_classifier_ algorithm \", source_data_label)\n",
    "    # Print the evaluation metrics\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F1 Score:\", f1)\n",
    "\n",
    "   \n",
    "    joblib.dump(svc, f\"si_3_without_orb_algo_zscore_on_ck_svm_classifier_{source_data_label}.joblib\")\n",
    "    # joblib.dump(svc, f\"lbp_zscore_on_ck_svm_classifier_{source_data_label}.joblib\")\n",
    "    # joblib.dump(svc, f\"hog_on_ck_svm_classifier_{source_data_label}.joblib\")\n",
    "    # joblib.dump(svc, f\"sift_on_ck_svm_classifier_{source_data_label}.joblib\")\n",
    "\n",
    "file_looper_transformer_extract_features_and_train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff0a1fb-6792-4f5b-a17e-426b09f4238b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815c44ff-94e3-4d5d-b6cf-965835f1f75e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
