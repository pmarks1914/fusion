{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "837dd289-d8d7-460b-b5eb-958a23fbff52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.7.2-cp310-cp310-macosx_11_0_arm64.whl (7.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m101.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:03\u001b[0mm\n",
      "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib) (4.40.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.20 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib) (1.25.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib) (9.1.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib) (3.0.8)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Installing collected packages: matplotlib\n",
      "Successfully installed matplotlib-3.7.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49fadaa3-d834-4a93-8397-7f79ee160446",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imgaug\n",
      "  Using cached imgaug-0.4.0-py2.py3-none-any.whl (948 kB)\n",
      "Requirement already satisfied: six in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from imgaug) (1.16.0)\n",
      "Requirement already satisfied: numpy>=1.15 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from imgaug) (1.24.3)\n",
      "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from imgaug) (1.10.1)\n",
      "Requirement already satisfied: Pillow in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from imgaug) (9.1.0)\n",
      "Requirement already satisfied: matplotlib in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from imgaug) (3.7.1)\n",
      "Requirement already satisfied: scikit-image>=0.14.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from imgaug) (0.21.0)\n",
      "Requirement already satisfied: opencv-python in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from imgaug) (4.7.0.72)\n",
      "Requirement already satisfied: imageio in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from imgaug) (2.31.1)\n",
      "Collecting Shapely (from imgaug)\n",
      "  Using cached shapely-2.0.1-cp310-cp310-macosx_11_0_arm64.whl (1.2 MB)\n",
      "Requirement already satisfied: networkx>=2.8 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from scikit-image>=0.14.2->imgaug) (3.1)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from scikit-image>=0.14.2->imgaug) (2023.4.12)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from scikit-image>=0.14.2->imgaug) (1.4.1)\n",
      "Requirement already satisfied: packaging>=21 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from scikit-image>=0.14.2->imgaug) (21.3)\n",
      "Requirement already satisfied: lazy_loader>=0.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from scikit-image>=0.14.2->imgaug) (0.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->imgaug) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->imgaug) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->imgaug) (4.40.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->imgaug) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->imgaug) (3.0.8)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->imgaug) (2.8.2)\n",
      "Installing collected packages: Shapely, imgaug\n",
      "Successfully installed Shapely-2.0.1 imgaug-0.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install imgaug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0857f7b0-7859-4749-8d32-643ea5b02039",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unsupported operand type(s) for /: 'NoneType' and 'int'\n",
      "Accuracy: 0.6294416243654822\n",
      "Precision: 0.5993255331822338\n",
      "Recall: 0.5677750271420349\n",
      "F1 Score: 0.5758044526417071\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from operator import le\n",
    "import cv2\n",
    "import dlib\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from imutils import face_utils\n",
    "from skimage.feature import hog, local_binary_pattern\n",
    "import mahotas as mh\n",
    "import joblib\n",
    "from sklearn import svm\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Resize descriptors to a consistent length\n",
    "desired_length = 1000\n",
    "# Initialize the label variable\n",
    "img_label = []\n",
    "feature_descriptors_fused = []\n",
    "\n",
    "\n",
    "def file_looper_transformer_extract_features_and_train():\n",
    "    source_data_label = \"\"\n",
    "    for dirname, _, filenames in os.walk('./ck'):\n",
    "        for filename in filenames:\n",
    "            # print(os.path.join(dirname, filename))\n",
    "            img_name, img_extention = os.path.splitext(filename)\n",
    "            expression_label = (os.path.join(dirname, filename)).split(os.sep)[2]\n",
    "            if source_data_label == '':\n",
    "                source_data_label = (os.path.join(dirname, filename)).split(os.sep)[1]\n",
    "\n",
    "            if(img_extention == \".jpg\" or img_extention == \".png\"):\n",
    "                image = cv2.imread(os.path.join(dirname, filename))\n",
    "                ext_feature, the_label = face_detection_extraction(image, expression_label)\n",
    "                feature_descriptors_fused.append(ext_feature)\n",
    "                img_label.append(expression_label)\n",
    "\n",
    "\n",
    "    # return feature_descriptors_fused, img_label\n",
    "    svmc(feature_descriptors_fused, img_label, source_data_label)\n",
    "\n",
    "\n",
    "def face_detection_extraction(image, image_label):\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = detector(gray, 1)\n",
    "    feature_list = []  # List to store the extracted features\n",
    "    label_list = []  # List to store the corresponding labels\n",
    "\n",
    "    for face in faces:\n",
    "        landmarks = predictor(gray, face)\n",
    "        x, y, w, h = face.left(), face.top(), face.width(), face.height()\n",
    "        extracted_face = image[y:y+h, x:x+w]\n",
    "        extracted_face = np.array(extracted_face)\n",
    "\n",
    "        shape = face_utils.shape_to_np(landmarks)\n",
    "        # Draw on our image, all the found 68 coordinate points (x,y)\n",
    "        for (x, y) in shape:\n",
    "            cv2.circle(image, (x, y), 2, (0, 255, 0), -1)\n",
    "        weight1 = 0.9  # Weight for descriptors lbp\n",
    "        weight2 = 0.9  # Weight for descriptors hog\n",
    "        weight3 = 0.2  # Weight for descriptors orb\n",
    "        weight4 = 0.2  # Weight for descriptors sift\n",
    "            \n",
    "        hog_descriptors = hog_extraction(extracted_face)\n",
    "        try:  \n",
    "            # Calculate the Z-scores for each descriptor\n",
    "            zscore_hog_descriptors = (hog_descriptors - np.mean(hog_descriptors)) / np.std(hog_descriptors)\n",
    "            # Fusion using weighted sum\n",
    "            hog_descriptors = weight2 * zscore_hog_descriptors   \n",
    "        except Exception as e:\n",
    "            # print(str(e), np.std(hog_descriptors))\n",
    "            pass    \n",
    "        hog_descriptors = np.resize(hog_descriptors, (desired_length,))\n",
    "\n",
    "        lbp_descriptors = lbp_extraction(extracted_face)\n",
    "        # Calculate the Z-scores for each descriptor\n",
    "        zscore_lbp_descriptors = (lbp_descriptors - np.mean(lbp_descriptors)) / np.std(lbp_descriptors)\n",
    "        # Fusion using weighted sum\n",
    "        lbp_descriptors = weight1 * zscore_lbp_descriptors \n",
    "        lbp_descriptors = np.resize(lbp_descriptors, (desired_length,))\n",
    "\n",
    "        orb_descriptors = orb_extraction(extracted_face)\n",
    "        # Calculate the Z-scores for each descriptor\n",
    "        # print(\" >>>\", np.std(orb_descriptors))\n",
    "        # print(\" <  > \", orb_descriptors - np.mean(orb_descriptors) )\n",
    "        try:\n",
    "            zscore_orb_descriptors = (orb_descriptors - np.mean(orb_descriptors)) / np.std(orb_descriptors)\n",
    "            # Fusion using weighted sum\n",
    "            orb_descriptors = weight3 * zscore_orb_descriptors \n",
    "            # print(\"orb_descriptors \", orb_descriptors)\n",
    "        except Exception as e:\n",
    "            print(str(e))\n",
    "            pass\n",
    "        orb_descriptors = np.resize(orb_descriptors, (desired_length,))\n",
    "\n",
    "        sift_descriptors = sift_extraction(extracted_face)\n",
    "        try:\n",
    "            # Calculate the Z-scores for each descriptor\n",
    "            zscore_sift_descriptors = (sift_descriptors - np.mean(sift_descriptors)) / np.std(sift_descriptors)\n",
    "            # Fusion using weighted sum\n",
    "            sift_descriptors = weight4 * zscore_sift_descriptors   \n",
    "        except Exception as e:\n",
    "            print(str(e))\n",
    "            pass    \n",
    "        sift_descriptors = np.resize(sift_descriptors, (desired_length,))\n",
    "\n",
    "        fused_features = sift_descriptors\n",
    "        # fused_features = np.concatenate((hog_descriptors, lbp_descriptors, orb_descriptors, sift_descriptors))\n",
    "\n",
    "        if len(fused_features) > 0:\n",
    "            feature_list.append(fused_features)\n",
    "            label_list.append(image_label)  # Add the label to the list\n",
    "\n",
    "    return feature_list, label_list\n",
    "\n",
    "        # print(fused_features)\n",
    "        \n",
    "        # Display the extracted faces\n",
    "        # cv2.imshow(\"Landmark localization\", extracted_face)\n",
    "        # plt.imshow(pixels)\n",
    "        # plt.axis('off')\n",
    "        # plt.show()\n",
    "\n",
    "def hog_extraction(extracted_face):\n",
    "    # Convert the image to grayscale\n",
    "    image_gray = cv2.cvtColor(extracted_face, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Define HOG parameters\n",
    "    orientations = 9  # Number of gradient orientations\n",
    "    pixels_per_cell = (8, 8)  # Cell size in pixels\n",
    "    cells_per_block = (2, 2)  # Number of cells in each block\n",
    "\n",
    "    # Compute HOG features\n",
    "    hog_image, hog_features = hog(image_gray, orientations=orientations, pixels_per_cell=pixels_per_cell, cells_per_block=cells_per_block, visualize=True)    \n",
    "    # print(hog_features)\n",
    "    disply_feature(\"HOG\", hog_features)\n",
    "    return hog_features\n",
    "\n",
    "def lbp_extraction(extracted_face):\n",
    "    # Compute LBP features\n",
    "\n",
    "    # Get the dimensions of the image\n",
    "    # height, width, channels = extracted_face.shape\n",
    "\n",
    "    # Compute LBP features\n",
    "    radius = 3\n",
    "    n_points = 8 * radius\n",
    "    # convert to 2 dimentional\n",
    "    extracted_face = cv2.cvtColor(extracted_face, cv2.COLOR_BGR2GRAY)\n",
    "    lbp_features = local_binary_pattern(extracted_face, n_points, radius, method='default')\n",
    "    # print(lbp_features)\n",
    "    disply_feature(\"LBP\", lbp_features)\n",
    "    return lbp_features\n",
    "\n",
    "# Scale-Invariant Feature Transform descriptor\n",
    "def sift_extraction(extracted_face):\n",
    "    # Create a SIFT object\n",
    "    sift = cv2.SIFT_create()\n",
    "    # Detect keypoints and compute descriptors\n",
    "    keypoints, descriptors = sift.detectAndCompute(extracted_face, None)\n",
    "    # Draw keypoints on the image\n",
    "    image_with_keypoints = cv2.drawKeypoints(extracted_face, keypoints, None)\n",
    "    # print(descriptors)\n",
    "    disply_feature(\"SIFT\", image_with_keypoints)\n",
    "    return descriptors\n",
    "\n",
    "def orb_extraction(extracted_face):\n",
    "    # Create an ORB object with custom parameters\n",
    "    orb = cv2.ORB_create(nfeatures=1000, scaleFactor=1.2, nlevels=8, edgeThreshold=15)\n",
    "    # Resize the extracted face to a larger size for better feature extraction\n",
    "    extracted_face = cv2.resize(extracted_face, (250, 250))\n",
    "    # Convert the face image to grayscale\n",
    "    extracted_face = cv2.cvtColor(extracted_face, cv2.COLOR_BGR2GRAY)\n",
    "    # Detect keypoints and compute descriptors\n",
    "    keypoints, descriptors = orb.detectAndCompute(extracted_face, None)\n",
    "    # Draw keypoints on the image\n",
    "    image_with_keypoints = cv2.drawKeypoints(extracted_face, keypoints, None, (0, 255, 0), cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "    # disply_feature(\"ORB\", image_with_keypoints)\n",
    "    return descriptors\n",
    "\n",
    "def disply_feature(features_type, features):\n",
    "    # cv2.imshow(features_type, features)\n",
    "    # # plt.imshow( features)\n",
    "    # plt.axis('off')\n",
    "    # plt.show()\n",
    "    pass\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "def svmc(fused_features, img_labels, source_data_label):\n",
    "    # Create arrays to store the features and labels\n",
    "    fused_features = np.array(fused_features)\n",
    "    img_labels = np.array(img_labels)\n",
    " \n",
    "    # Reshape the fused features to have two dimensions\n",
    "    fused_features = fused_features.reshape(fused_features.shape[0], -1)\n",
    "\n",
    "    # Normalize the feature vectors\n",
    "    scaler = StandardScaler()\n",
    "    fused_features = scaler.fit_transform(fused_features)\n",
    "\n",
    "    # Handle missing values with an imputer transformer\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    fused_features = imputer.fit_transform(fused_features)\n",
    "\n",
    "    # Split the fused features data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(fused_features, img_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Create an SVM classifier\n",
    "    # instantiate classifier with linear kernel and C=100\n",
    "    svc = svm.SVC(kernel='linear', C=100)\n",
    "\n",
    "    # Train the classifier\n",
    "    svc.fit(X_train, y_train)\n",
    "\n",
    "    # Predict labels for the test set\n",
    "    y_pred = svc.predict(X_test)\n",
    "    # print(y_pred)\n",
    "    # print(\"< ---------------- >\")\n",
    "    # print(y_test)\n",
    "    # print(\"< ---------------- >\")\n",
    "    # print(X_train)\n",
    "    # print(\"< ---------------- >\")\n",
    "    # print(X_test)\n",
    "\n",
    "    # Evaluate the classifier's performance\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='macro', zero_division=1)\n",
    "    recall = recall_score(y_test, y_pred, average='macro', zero_division=1)\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    # Print the evaluation metrics\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F1 Score:\", f1)\n",
    "\n",
    "   \n",
    "    joblib.dump(svc, f\"sift_zscore_on_ck_svm_classifier_{source_data_label}.joblib\")\n",
    "    # joblib.dump(svc, f\"lbp_zscore_on_ck_svm_classifier_{source_data_label}.joblib\")\n",
    "    # joblib.dump(svc, f\"hog_on_ck_svm_classifier_{source_data_label}.joblib\")\n",
    "    # joblib.dump(svc, f\"sift_on_ck_svm_classifier_{source_data_label}.joblib\")\n",
    "\n",
    "file_looper_transformer_extract_features_and_train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fec0ac97-8314-4975-867d-89363d75e3ae",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unsupported operand type(s) for /: 'NoneType' and 'int'\n",
      "Accuracy: 0.9441624365482234\n",
      "Precision: 0.9208335910121624\n",
      "Recall: 0.9272525481764612\n",
      "F1 Score: 0.9226172147687494\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from operator import le\n",
    "import cv2\n",
    "import dlib\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from imutils import face_utils\n",
    "from skimage.feature import hog, local_binary_pattern\n",
    "import mahotas as mh\n",
    "import joblib\n",
    "from sklearn import svm\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Resize descriptors to a consistent length\n",
    "desired_length = 1000\n",
    "# Initialize the label variable\n",
    "img_label = []\n",
    "feature_descriptors_fused = []\n",
    "\n",
    "\n",
    "def file_looper_transformer_extract_features_and_train():\n",
    "    source_data_label = \"\"\n",
    "    for dirname, _, filenames in os.walk('./ck'):\n",
    "        for filename in filenames:\n",
    "            # print(os.path.join(dirname, filename))\n",
    "            img_name, img_extention = os.path.splitext(filename)\n",
    "            expression_label = (os.path.join(dirname, filename)).split(os.sep)[2]\n",
    "            if source_data_label == '':\n",
    "                source_data_label = (os.path.join(dirname, filename)).split(os.sep)[1]\n",
    "\n",
    "            if(img_extention == \".jpg\" or img_extention == \".png\"):\n",
    "                image = cv2.imread(os.path.join(dirname, filename))\n",
    "                ext_feature, the_label = face_detection_extraction(image, expression_label)\n",
    "                feature_descriptors_fused.append(ext_feature)\n",
    "                img_label.append(expression_label)\n",
    "\n",
    "\n",
    "    # return feature_descriptors_fused, img_label\n",
    "    svmc(feature_descriptors_fused, img_label, source_data_label)\n",
    "\n",
    "\n",
    "def face_detection_extraction(image, image_label):\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = detector(gray, 1)\n",
    "    feature_list = []  # List to store the extracted features\n",
    "    label_list = []  # List to store the corresponding labels\n",
    "\n",
    "    for face in faces:\n",
    "        landmarks = predictor(gray, face)\n",
    "        x, y, w, h = face.left(), face.top(), face.width(), face.height()\n",
    "        extracted_face = image[y:y+h, x:x+w]\n",
    "        extracted_face = np.array(extracted_face)\n",
    "\n",
    "        shape = face_utils.shape_to_np(landmarks)\n",
    "        # Draw on our image, all the found 68 coordinate points (x,y)\n",
    "        for (x, y) in shape:\n",
    "            cv2.circle(image, (x, y), 2, (0, 255, 0), -1)\n",
    "        weight1 = 0.9  # Weight for descriptors lbp\n",
    "        weight2 = 0.9  # Weight for descriptors hog\n",
    "        weight3 = 0.2  # Weight for descriptors orb\n",
    "        weight4 = 0.2  # Weight for descriptors sift\n",
    "            \n",
    "        hog_descriptors = hog_extraction(extracted_face)\n",
    "        try:  \n",
    "            # Calculate the Z-scores for each descriptor\n",
    "            zscore_hog_descriptors = (hog_descriptors - np.mean(hog_descriptors)) / np.std(hog_descriptors)\n",
    "            # Fusion using weighted sum\n",
    "            hog_descriptors = weight2 * zscore_hog_descriptors   \n",
    "        except Exception as e:\n",
    "            # print(str(e), np.std(hog_descriptors))\n",
    "            pass    \n",
    "        hog_descriptors = np.resize(hog_descriptors, (desired_length,))\n",
    "\n",
    "        lbp_descriptors = lbp_extraction(extracted_face)\n",
    "        # Calculate the Z-scores for each descriptor\n",
    "        zscore_lbp_descriptors = (lbp_descriptors - np.mean(lbp_descriptors)) / np.std(lbp_descriptors)\n",
    "        # Fusion using weighted sum\n",
    "        lbp_descriptors = weight1 * zscore_lbp_descriptors \n",
    "        lbp_descriptors = np.resize(lbp_descriptors, (desired_length,))\n",
    "\n",
    "        orb_descriptors = orb_extraction(extracted_face)\n",
    "        # Calculate the Z-scores for each descriptor\n",
    "        # print(\" >>>\", np.std(orb_descriptors))\n",
    "        # print(\" <  > \", orb_descriptors - np.mean(orb_descriptors) )\n",
    "        try:\n",
    "            zscore_orb_descriptors = (orb_descriptors - np.mean(orb_descriptors)) / np.std(orb_descriptors)\n",
    "            # Fusion using weighted sum\n",
    "            orb_descriptors = weight3 * zscore_orb_descriptors \n",
    "            # print(\"orb_descriptors \", orb_descriptors)\n",
    "        except Exception as e:\n",
    "            print(str(e))\n",
    "            pass\n",
    "        orb_descriptors = np.resize(orb_descriptors, (desired_length,))\n",
    "\n",
    "        sift_descriptors = sift_extraction(extracted_face)\n",
    "        try:\n",
    "            # Calculate the Z-scores for each descriptor\n",
    "            zscore_sift_descriptors = (sift_descriptors - np.mean(sift_descriptors)) / np.std(sift_descriptors)\n",
    "            # Fusion using weighted sum\n",
    "            sift_descriptors = weight4 * zscore_sift_descriptors   \n",
    "        except Exception as e:\n",
    "            print(str(e))\n",
    "            pass    \n",
    "        sift_descriptors = np.resize(sift_descriptors, (desired_length,))\n",
    "\n",
    "        fused_features = hog_descriptors\n",
    "        # fused_features = np.concatenate((hog_descriptors, lbp_descriptors, orb_descriptors, sift_descriptors))\n",
    "\n",
    "        if len(fused_features) > 0:\n",
    "            feature_list.append(fused_features)\n",
    "            label_list.append(image_label)  # Add the label to the list\n",
    "\n",
    "    return feature_list, label_list\n",
    "\n",
    "        # print(fused_features)\n",
    "        \n",
    "        # Display the extracted faces\n",
    "        # cv2.imshow(\"Landmark localization\", extracted_face)\n",
    "        # plt.imshow(pixels)\n",
    "        # plt.axis('off')\n",
    "        # plt.show()\n",
    "\n",
    "def hog_extraction(extracted_face):\n",
    "    # Convert the image to grayscale\n",
    "    image_gray = cv2.cvtColor(extracted_face, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Define HOG parameters\n",
    "    orientations = 9  # Number of gradient orientations\n",
    "    pixels_per_cell = (8, 8)  # Cell size in pixels\n",
    "    cells_per_block = (2, 2)  # Number of cells in each block\n",
    "\n",
    "    # Compute HOG features\n",
    "    hog_image, hog_features = hog(image_gray, orientations=orientations, pixels_per_cell=pixels_per_cell, cells_per_block=cells_per_block, visualize=True)    \n",
    "    # print(hog_features)\n",
    "    disply_feature(\"HOG\", hog_features)\n",
    "    return hog_features\n",
    "\n",
    "def lbp_extraction(extracted_face):\n",
    "    # Compute LBP features\n",
    "\n",
    "    # Get the dimensions of the image\n",
    "    # height, width, channels = extracted_face.shape\n",
    "\n",
    "    # Compute LBP features\n",
    "    radius = 3\n",
    "    n_points = 8 * radius\n",
    "    # convert to 2 dimentional\n",
    "    extracted_face = cv2.cvtColor(extracted_face, cv2.COLOR_BGR2GRAY)\n",
    "    lbp_features = local_binary_pattern(extracted_face, n_points, radius, method='default')\n",
    "    # print(lbp_features)\n",
    "    disply_feature(\"LBP\", lbp_features)\n",
    "    return lbp_features\n",
    "\n",
    "# Scale-Invariant Feature Transform descriptor\n",
    "def sift_extraction(extracted_face):\n",
    "    # Create a SIFT object\n",
    "    sift = cv2.SIFT_create()\n",
    "    # Detect keypoints and compute descriptors\n",
    "    keypoints, descriptors = sift.detectAndCompute(extracted_face, None)\n",
    "    # Draw keypoints on the image\n",
    "    image_with_keypoints = cv2.drawKeypoints(extracted_face, keypoints, None)\n",
    "    # print(descriptors)\n",
    "    disply_feature(\"SIFT\", image_with_keypoints)\n",
    "    return descriptors\n",
    "\n",
    "def orb_extraction(extracted_face):\n",
    "    # Create an ORB object with custom parameters\n",
    "    orb = cv2.ORB_create(nfeatures=1000, scaleFactor=1.2, nlevels=8, edgeThreshold=15)\n",
    "    # Resize the extracted face to a larger size for better feature extraction\n",
    "    extracted_face = cv2.resize(extracted_face, (250, 250))\n",
    "    # Convert the face image to grayscale\n",
    "    extracted_face = cv2.cvtColor(extracted_face, cv2.COLOR_BGR2GRAY)\n",
    "    # Detect keypoints and compute descriptors\n",
    "    keypoints, descriptors = orb.detectAndCompute(extracted_face, None)\n",
    "    # Draw keypoints on the image\n",
    "    image_with_keypoints = cv2.drawKeypoints(extracted_face, keypoints, None, (0, 255, 0), cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "    # disply_feature(\"ORB\", image_with_keypoints)\n",
    "    return descriptors\n",
    "\n",
    "def disply_feature(features_type, features):\n",
    "    # cv2.imshow(features_type, features)\n",
    "    # # plt.imshow( features)\n",
    "    # plt.axis('off')\n",
    "    # plt.show()\n",
    "    pass\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "def svmc(fused_features, img_labels, source_data_label):\n",
    "    # Create arrays to store the features and labels\n",
    "    fused_features = np.array(fused_features)\n",
    "    img_labels = np.array(img_labels)\n",
    " \n",
    "    # Reshape the fused features to have two dimensions\n",
    "    fused_features = fused_features.reshape(fused_features.shape[0], -1)\n",
    "\n",
    "    # Normalize the feature vectors\n",
    "    scaler = StandardScaler()\n",
    "    fused_features = scaler.fit_transform(fused_features)\n",
    "\n",
    "    # Handle missing values with an imputer transformer\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    fused_features = imputer.fit_transform(fused_features)\n",
    "\n",
    "    # Split the fused features data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(fused_features, img_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Create an SVM classifier\n",
    "    # instantiate classifier with linear kernel and C=100\n",
    "    svc = svm.SVC(kernel='linear', C=100)\n",
    "\n",
    "    # Train the classifier\n",
    "    svc.fit(X_train, y_train)\n",
    "\n",
    "    # Predict labels for the test set\n",
    "    y_pred = svc.predict(X_test)\n",
    "    # print(y_pred)\n",
    "    # print(\"< ---------------- >\")\n",
    "    # print(y_test)\n",
    "    # print(\"< ---------------- >\")\n",
    "    # print(X_train)\n",
    "    # print(\"< ---------------- >\")\n",
    "    # print(X_test)\n",
    "\n",
    "    # Evaluate the classifier's performance\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='macro', zero_division=1)\n",
    "    recall = recall_score(y_test, y_pred, average='macro', zero_division=1)\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    # Print the evaluation metrics\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F1 Score:\", f1)\n",
    "\n",
    "   \n",
    "    joblib.dump(svc, f\"hog_zscore_on_ck_svm_classifier_{source_data_label}.joblib\")\n",
    "    # joblib.dump(svc, f\"lbp_zscore_on_ck_svm_classifier_{source_data_label}.joblib\")\n",
    "    # joblib.dump(svc, f\"hog_on_ck_svm_classifier_{source_data_label}.joblib\")\n",
    "    # joblib.dump(svc, f\"sift_on_ck_svm_classifier_{source_data_label}.joblib\")\n",
    "\n",
    "file_looper_transformer_extract_features_and_train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "25c1825a-88cf-4108-b1aa-18c48830d0eb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unsupported operand type(s) for /: 'NoneType' and 'int'\n",
      " 4 algorithm \n",
      "Accuracy: 0.949238578680203\n",
      "Precision: 0.9572955115060379\n",
      "Recall: 0.923334551211789\n",
      "F1 Score: 0.9368567510769232\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from operator import le\n",
    "import cv2\n",
    "import dlib\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from imutils import face_utils\n",
    "from skimage.feature import hog, local_binary_pattern\n",
    "import mahotas as mh\n",
    "import joblib\n",
    "from sklearn import svm\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Resize descriptors to a consistent length\n",
    "desired_length = 1000\n",
    "# Initialize the label variable\n",
    "img_label = []\n",
    "feature_descriptors_fused = []\n",
    "\n",
    "\n",
    "def file_looper_transformer_extract_features_and_train():\n",
    "    source_data_label = \"\"\n",
    "    for dirname, _, filenames in os.walk('./ck'):\n",
    "        for filename in filenames:\n",
    "            # print(os.path.join(dirname, filename))\n",
    "            img_name, img_extention = os.path.splitext(filename)\n",
    "            expression_label = (os.path.join(dirname, filename)).split(os.sep)[2]\n",
    "            if source_data_label == '':\n",
    "                source_data_label = (os.path.join(dirname, filename)).split(os.sep)[1]\n",
    "\n",
    "            if(img_extention == \".jpg\" or img_extention == \".png\"):\n",
    "                image = cv2.imread(os.path.join(dirname, filename))\n",
    "                ext_feature, the_label = face_detection_extraction(image, expression_label)\n",
    "                feature_descriptors_fused.append(ext_feature)\n",
    "                img_label.append(expression_label)\n",
    "\n",
    "\n",
    "    # return feature_descriptors_fused, img_label\n",
    "    svmc(feature_descriptors_fused, img_label, source_data_label)\n",
    "\n",
    "\n",
    "def face_detection_extraction(image, image_label):\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = detector(gray, 1)\n",
    "    feature_list = []  # List to store the extracted features\n",
    "    label_list = []  # List to store the corresponding labels\n",
    "\n",
    "    for face in faces:\n",
    "        landmarks = predictor(gray, face)\n",
    "        x, y, w, h = face.left(), face.top(), face.width(), face.height()\n",
    "        extracted_face = image[y:y+h, x:x+w]\n",
    "        extracted_face = np.array(extracted_face)\n",
    "\n",
    "        shape = face_utils.shape_to_np(landmarks)\n",
    "        # Draw on our image, all the found 68 coordinate points (x,y)\n",
    "        for (x, y) in shape:\n",
    "            cv2.circle(image, (x, y), 2, (0, 255, 0), -1)\n",
    "        weight1 = 0.9  # Weight for descriptors lbp\n",
    "        weight2 = 0.9  # Weight for descriptors hog\n",
    "        weight3 = 0.2  # Weight for descriptors orb\n",
    "        weight4 = 0.2  # Weight for descriptors sift\n",
    "            \n",
    "        hog_descriptors = hog_extraction(extracted_face)\n",
    "        try:  \n",
    "            # Calculate the Z-scores for each descriptor\n",
    "            zscore_hog_descriptors = (hog_descriptors - np.mean(hog_descriptors)) / np.std(hog_descriptors)\n",
    "            # Fusion using weighted sum\n",
    "            hog_descriptors = weight2 * zscore_hog_descriptors   \n",
    "        except Exception as e:\n",
    "            # print(str(e), np.std(hog_descriptors))\n",
    "            pass    \n",
    "        hog_descriptors = np.resize(hog_descriptors, (desired_length,))\n",
    "\n",
    "        lbp_descriptors = lbp_extraction(extracted_face)\n",
    "        # Calculate the Z-scores for each descriptor\n",
    "        zscore_lbp_descriptors = (lbp_descriptors - np.mean(lbp_descriptors)) / np.std(lbp_descriptors)\n",
    "        # Fusion using weighted sum\n",
    "        lbp_descriptors = weight1 * zscore_lbp_descriptors \n",
    "        lbp_descriptors = np.resize(lbp_descriptors, (desired_length,))\n",
    "\n",
    "        orb_descriptors = orb_extraction(extracted_face)\n",
    "        # Calculate the Z-scores for each descriptor\n",
    "        # print(\" >>>\", np.std(orb_descriptors))\n",
    "        # print(\" <  > \", orb_descriptors - np.mean(orb_descriptors) )\n",
    "        try:\n",
    "            zscore_orb_descriptors = (orb_descriptors - np.mean(orb_descriptors)) / np.std(orb_descriptors)\n",
    "            # Fusion using weighted sum\n",
    "            orb_descriptors = weight3 * zscore_orb_descriptors \n",
    "            # print(\"orb_descriptors \", orb_descriptors)\n",
    "        except Exception as e:\n",
    "            print(str(e))\n",
    "            pass\n",
    "        orb_descriptors = np.resize(orb_descriptors, (desired_length,))\n",
    "\n",
    "        sift_descriptors = sift_extraction(extracted_face)\n",
    "        try:\n",
    "            # Calculate the Z-scores for each descriptor\n",
    "            zscore_sift_descriptors = (sift_descriptors - np.mean(sift_descriptors)) / np.std(sift_descriptors)\n",
    "            # Fusion using weighted sum\n",
    "            sift_descriptors = weight4 * zscore_sift_descriptors   \n",
    "        except Exception as e:\n",
    "            print(str(e))\n",
    "            pass    \n",
    "        sift_descriptors = np.resize(sift_descriptors, (desired_length,))\n",
    "\n",
    "        # fused_features = hog_descriptors\n",
    "        fused_features = np.concatenate((hog_descriptors, lbp_descriptors, orb_descriptors, sift_descriptors))\n",
    "\n",
    "        if len(fused_features) > 0:\n",
    "            feature_list.append(fused_features)\n",
    "            label_list.append(image_label)  # Add the label to the list\n",
    "\n",
    "    return feature_list, label_list\n",
    "\n",
    "        # print(fused_features)\n",
    "        \n",
    "        # Display the extracted faces\n",
    "        # cv2.imshow(\"Landmark localization\", extracted_face)\n",
    "        # plt.imshow(pixels)\n",
    "        # plt.axis('off')\n",
    "        # plt.show()\n",
    "\n",
    "def hog_extraction(extracted_face):\n",
    "    # Convert the image to grayscale\n",
    "    image_gray = cv2.cvtColor(extracted_face, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Define HOG parameters\n",
    "    orientations = 9  # Number of gradient orientations\n",
    "    pixels_per_cell = (8, 8)  # Cell size in pixels\n",
    "    cells_per_block = (2, 2)  # Number of cells in each block\n",
    "\n",
    "    # Compute HOG features\n",
    "    hog_image, hog_features = hog(image_gray, orientations=orientations, pixels_per_cell=pixels_per_cell, cells_per_block=cells_per_block, visualize=True)    \n",
    "    # print(hog_features)\n",
    "    disply_feature(\"HOG\", hog_features)\n",
    "    return hog_features\n",
    "\n",
    "def lbp_extraction(extracted_face):\n",
    "    # Compute LBP features\n",
    "\n",
    "    # Get the dimensions of the image\n",
    "    # height, width, channels = extracted_face.shape\n",
    "\n",
    "    # Compute LBP features\n",
    "    radius = 3\n",
    "    n_points = 8 * radius\n",
    "    # convert to 2 dimentional\n",
    "    extracted_face = cv2.cvtColor(extracted_face, cv2.COLOR_BGR2GRAY)\n",
    "    lbp_features = local_binary_pattern(extracted_face, n_points, radius, method='default')\n",
    "    # print(lbp_features)\n",
    "    disply_feature(\"LBP\", lbp_features)\n",
    "    return lbp_features\n",
    "\n",
    "# Scale-Invariant Feature Transform descriptor\n",
    "def sift_extraction(extracted_face):\n",
    "    # Create a SIFT object\n",
    "    sift = cv2.SIFT_create()\n",
    "    # Detect keypoints and compute descriptors\n",
    "    keypoints, descriptors = sift.detectAndCompute(extracted_face, None)\n",
    "    # Draw keypoints on the image\n",
    "    image_with_keypoints = cv2.drawKeypoints(extracted_face, keypoints, None)\n",
    "    # print(descriptors)\n",
    "    disply_feature(\"SIFT\", image_with_keypoints)\n",
    "    return descriptors\n",
    "\n",
    "def orb_extraction(extracted_face):\n",
    "    # Create an ORB object with custom parameters\n",
    "    orb = cv2.ORB_create(nfeatures=1000, scaleFactor=1.2, nlevels=8, edgeThreshold=15)\n",
    "    # Resize the extracted face to a larger size for better feature extraction\n",
    "    extracted_face = cv2.resize(extracted_face, (250, 250))\n",
    "    # Convert the face image to grayscale\n",
    "    extracted_face = cv2.cvtColor(extracted_face, cv2.COLOR_BGR2GRAY)\n",
    "    # Detect keypoints and compute descriptors\n",
    "    keypoints, descriptors = orb.detectAndCompute(extracted_face, None)\n",
    "    # Draw keypoints on the image\n",
    "    image_with_keypoints = cv2.drawKeypoints(extracted_face, keypoints, None, (0, 255, 0), cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "    # disply_feature(\"ORB\", image_with_keypoints)\n",
    "    return descriptors\n",
    "\n",
    "def disply_feature(features_type, features):\n",
    "    # cv2.imshow(features_type, features)\n",
    "    # # plt.imshow( features)\n",
    "    # plt.axis('off')\n",
    "    # plt.show()\n",
    "    pass\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "def svmc(fused_features, img_labels, source_data_label):\n",
    "    # Create arrays to store the features and labels\n",
    "    fused_features = np.array(fused_features)\n",
    "    img_labels = np.array(img_labels)\n",
    " \n",
    "    # Reshape the fused features to have two dimensions\n",
    "    fused_features = fused_features.reshape(fused_features.shape[0], -1)\n",
    "\n",
    "    # Normalize the feature vectors\n",
    "    scaler = StandardScaler()\n",
    "    fused_features = scaler.fit_transform(fused_features)\n",
    "\n",
    "    # Handle missing values with an imputer transformer\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    fused_features = imputer.fit_transform(fused_features)\n",
    "\n",
    "    # Split the fused features data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(fused_features, img_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Create an SVM classifier\n",
    "    # instantiate classifier with linear kernel and C=100\n",
    "    svc = svm.SVC(kernel='linear', C=100)\n",
    "\n",
    "    # Train the classifier\n",
    "    svc.fit(X_train, y_train)\n",
    "\n",
    "    # Predict labels for the test set\n",
    "    y_pred = svc.predict(X_test)\n",
    "    # print(y_pred)\n",
    "    # print(\"< ---------------- >\")\n",
    "    # print(y_test)\n",
    "    # print(\"< ---------------- >\")\n",
    "    # print(X_train)\n",
    "    # print(\"< ---------------- >\")\n",
    "    # print(X_test)\n",
    "\n",
    "    # Evaluate the classifier's performance\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='macro', zero_division=1)\n",
    "    recall = recall_score(y_test, y_pred, average='macro', zero_division=1)\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    print(\" 4 algorithm \")\n",
    "    # Print the evaluation metrics\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F1 Score:\", f1)\n",
    "\n",
    "   \n",
    "    joblib.dump(svc, f\"4_algo_zscore_on_ck_svm_classifier_{source_data_label}.joblib\")\n",
    "    # joblib.dump(svc, f\"lbp_zscore_on_ck_svm_classifier_{source_data_label}.joblib\")\n",
    "    # joblib.dump(svc, f\"hog_on_ck_svm_classifier_{source_data_label}.joblib\")\n",
    "    # joblib.dump(svc, f\"sift_on_ck_svm_classifier_{source_data_label}.joblib\")\n",
    "\n",
    "file_looper_transformer_extract_features_and_train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4e80b349-54e3-4e93-97f8-99d110a97e08",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 3_without_orb_algo algorithm \n",
      "Accuracy: 0.9872881355932204\n",
      "Precision: 0.9766233766233767\n",
      "Recall: 0.9794050776809398\n",
      "F1 Score: 0.9774916387959866\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from operator import le\n",
    "import cv2\n",
    "import dlib\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from imutils import face_utils\n",
    "from skimage.feature import hog, local_binary_pattern\n",
    "import mahotas as mh\n",
    "import joblib\n",
    "from sklearn import svm\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import imgaug.augmenters as iaa\n",
    "\n",
    "# Resize descriptors to a consistent length\n",
    "desired_length = 1000\n",
    "# Initialize the label variable\n",
    "img_label = []\n",
    "feature_descriptors_fused = []\n",
    "\n",
    "\n",
    "def file_looper_transformer_extract_features_and_train():\n",
    "    source_data_label = \"\"\n",
    "    augmentation_seq = iaa.Sequential([\n",
    "        # iaa.Fliplr(),  # Flip images horizontally with a 50% chance\n",
    "        # iaa.Multiply((0.8, 1.2)),  # Multiply pixel values by a factor between 0.8 and 1.2\n",
    "        # iaa.GammaContrast(),  # Adjust gamma contrast between 0.8 and 1.2\n",
    "        # iaa.ElasticTransformation(alpha=50, sigma=5)  # Apply elastic transformations\n",
    "        iaa.Affine(rotate=(0, 10)),  # Rotate images by -10 to +10 degrees\n",
    "        # iaa.GaussianBlur(sigma=(0, 1.0)),  # Apply Gaussian blur with a sigma between 0 and 1.0\n",
    "        # iaa.AdditiveGaussianNoise(scale=(0, 0.05*255)),  # Add Gaussian noise with a scale of 0 to 0.05*255\n",
    "    ])\n",
    "    for dirname, _, filenames in os.walk('./ck'):\n",
    "        for filename in filenames:\n",
    "            # print(os.path.join(dirname, filename))\n",
    "            img_name, img_extention = os.path.splitext(filename)\n",
    "            expression_label = (os.path.join(dirname, filename)).split(os.sep)[2]\n",
    "            if source_data_label == '':\n",
    "                source_data_label = (os.path.join(dirname, filename)).split(os.sep)[1]\n",
    "\n",
    "            if(img_extention == \".jpg\" or img_extention == \".png\"):\n",
    "                image = cv2.imread(os.path.join(dirname, filename))\n",
    "                # Apply data augmentation\n",
    "                # image = augmentation_seq(image=image)\n",
    "                \n",
    "                ext_feature, the_label = face_detection_extraction(image, expression_label)\n",
    "                feature_descriptors_fused.append(ext_feature)\n",
    "                img_label.append(expression_label)\n",
    "\n",
    "\n",
    "    # return feature_descriptors_fused, img_label\n",
    "    svmc(feature_descriptors_fused, img_label, source_data_label)\n",
    "\n",
    "\n",
    "def face_detection_extraction(image, image_label):\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = detector(gray, 1)\n",
    "    feature_list = []  # List to store the extracted features\n",
    "    label_list = []  # List to store the corresponding labels\n",
    "\n",
    "    for face in faces:\n",
    "        landmarks = predictor(gray, face)\n",
    "        x, y, w, h = face.left(), face.top(), face.width(), face.height()\n",
    "        extracted_face = image[y:y+h, x:x+w]\n",
    "        extracted_face = np.array(extracted_face)\n",
    "\n",
    "        shape = face_utils.shape_to_np(landmarks)\n",
    "        # Draw on our image, all the found 68 coordinate points (x,y)\n",
    "        for (x, y) in shape:\n",
    "            cv2.circle(image, (x, y), 2, (0, 255, 0), -1)\n",
    "        weight1 = 0.9  # Weight for descriptors lbp\n",
    "        weight2 = 0.9  # Weight for descriptors hog\n",
    "        weight3 = 0.2  # Weight for descriptors orb\n",
    "        weight4 = 0.2  # Weight for descriptors sift\n",
    "            \n",
    "        hog_descriptors = hog_extraction(extracted_face)\n",
    "        try:  \n",
    "            # Calculate the Z-scores for each descriptor\n",
    "            zscore_hog_descriptors = (hog_descriptors - np.mean(hog_descriptors)) / np.std(hog_descriptors)\n",
    "            # Fusion using weighted sum\n",
    "            hog_descriptors = weight2 * zscore_hog_descriptors   \n",
    "        except Exception as e:\n",
    "            # print(str(e), np.std(hog_descriptors))\n",
    "            pass    \n",
    "        hog_descriptors = np.resize(hog_descriptors, (desired_length,))\n",
    "\n",
    "        lbp_descriptors = lbp_extraction(extracted_face)\n",
    "        # Calculate the Z-scores for each descriptor\n",
    "        zscore_lbp_descriptors = (lbp_descriptors - np.mean(lbp_descriptors)) / np.std(lbp_descriptors)\n",
    "        # Fusion using weighted sum\n",
    "        lbp_descriptors = weight1 * zscore_lbp_descriptors \n",
    "        lbp_descriptors = np.resize(lbp_descriptors, (desired_length,))\n",
    "\n",
    "        orb_descriptors = orb_extraction(extracted_face)\n",
    "        # Calculate the Z-scores for each descriptor\n",
    "        # print(\" >>>\", np.std(orb_descriptors))\n",
    "        # print(\" <  > \", orb_descriptors - np.mean(orb_descriptors) )\n",
    "        try:\n",
    "            zscore_orb_descriptors = (orb_descriptors - np.mean(orb_descriptors)) / np.std(orb_descriptors)\n",
    "            # Fusion using weighted sum\n",
    "            orb_descriptors = weight3 * zscore_orb_descriptors \n",
    "            # print(\"orb_descriptors \", orb_descriptors)\n",
    "        except Exception as e:\n",
    "            # print(str(e))\n",
    "            pass\n",
    "        orb_descriptors = np.resize(orb_descriptors, (desired_length,))\n",
    "\n",
    "        sift_descriptors = sift_extraction(extracted_face)\n",
    "        try:\n",
    "            # Calculate the Z-scores for each descriptor\n",
    "            zscore_sift_descriptors = (sift_descriptors - np.mean(sift_descriptors)) / np.std(sift_descriptors)\n",
    "            # Fusion using weighted sum\n",
    "            sift_descriptors = weight4 * zscore_sift_descriptors   \n",
    "        except Exception as e:\n",
    "            # print(str(e))\n",
    "            pass    \n",
    "        sift_descriptors = np.resize(sift_descriptors, (desired_length,))\n",
    "\n",
    "        # fused_features = lbp_descriptors + hog_descriptors + sift_descriptors\n",
    "        fused_features = hog_descriptors\n",
    "        if lbp_descriptors is not None:\n",
    "            fused_features += lbp_descriptors\n",
    "        if sift_descriptors is not None:\n",
    "            fused_features += sift_descriptors.astype(np.float64)\n",
    "\n",
    "        # fused_features = np.concatenate((hog_descriptors, lbp_descriptors, sift_descriptors))\n",
    "\n",
    "        if len(fused_features) > 0:\n",
    "            feature_list.append(fused_features)\n",
    "            label_list.append(image_label)  # Add the label to the list\n",
    "\n",
    "    return feature_list, label_list\n",
    "\n",
    "        # print(fused_features)\n",
    "        \n",
    "        # Display the extracted faces\n",
    "        # cv2.imshow(\"Landmark localization\", extracted_face)\n",
    "        # plt.imshow(pixels)\n",
    "        # plt.axis('off')\n",
    "        # plt.show()\n",
    "\n",
    "def hog_extraction(extracted_face):\n",
    "    # Convert the image to grayscale\n",
    "    image_gray = cv2.cvtColor(extracted_face, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Define HOG parameters\n",
    "    orientations = 9  # Number of gradient orientations\n",
    "    pixels_per_cell = (8, 8)  # Cell size in pixels\n",
    "    cells_per_block = (2, 2)  # Number of cells in each block\n",
    "\n",
    "    # Compute HOG features\n",
    "    hog_image, hog_features = hog(image_gray, orientations=orientations, pixels_per_cell=pixels_per_cell, cells_per_block=cells_per_block, visualize=True)    \n",
    "    # print(hog_features)\n",
    "    disply_feature(\"HOG\", hog_features)\n",
    "    return hog_features\n",
    "\n",
    "def lbp_extraction(extracted_face):\n",
    "    # Compute LBP features\n",
    "\n",
    "    # Get the dimensions of the image\n",
    "    # height, width, channels = extracted_face.shape\n",
    "\n",
    "    # Compute LBP features\n",
    "    radius = 3\n",
    "    n_points = 8 * radius\n",
    "    # convert to 2 dimentional\n",
    "    extracted_face = cv2.cvtColor(extracted_face, cv2.COLOR_BGR2GRAY)\n",
    "    lbp_features = local_binary_pattern(extracted_face, n_points, radius, method='default')\n",
    "    # print(lbp_features)\n",
    "    disply_feature(\"LBP\", lbp_features)\n",
    "    return lbp_features\n",
    "\n",
    "# Scale-Invariant Feature Transform descriptor\n",
    "def sift_extraction(extracted_face):\n",
    "    # Create a SIFT object\n",
    "    sift = cv2.SIFT_create()\n",
    "    # Detect keypoints and compute descriptors\n",
    "    keypoints, descriptors = sift.detectAndCompute(extracted_face, None)\n",
    "    # Draw keypoints on the image\n",
    "    image_with_keypoints = cv2.drawKeypoints(extracted_face, keypoints, None)\n",
    "    # print(descriptors)\n",
    "    disply_feature(\"SIFT\", image_with_keypoints)\n",
    "    return descriptors\n",
    "\n",
    "def orb_extraction(extracted_face):\n",
    "    # Create an ORB object with custom parameters\n",
    "    orb = cv2.ORB_create(nfeatures=1000, scaleFactor=1.2, nlevels=8, edgeThreshold=15)\n",
    "    # Resize the extracted face to a larger size for better feature extraction\n",
    "    extracted_face = cv2.resize(extracted_face, (250, 250))\n",
    "    # Convert the face image to grayscale\n",
    "    extracted_face = cv2.cvtColor(extracted_face, cv2.COLOR_BGR2GRAY)\n",
    "    # Detect keypoints and compute descriptors\n",
    "    keypoints, descriptors = orb.detectAndCompute(extracted_face, None)\n",
    "    # Draw keypoints on the image\n",
    "    image_with_keypoints = cv2.drawKeypoints(extracted_face, keypoints, None, (0, 255, 0), cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "    # disply_feature(\"ORB\", image_with_keypoints)\n",
    "    return descriptors\n",
    "\n",
    "def disply_feature(features_type, features):\n",
    "    # cv2.imshow(features_type, features)\n",
    "    # # plt.imshow( features)\n",
    "    # plt.axis('off')\n",
    "    # plt.show()\n",
    "    pass\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "def svmc(fused_features, img_labels, source_data_label):\n",
    "    \n",
    "    # Create arrays to store the features and labels\n",
    "    fused_features = np.array(fused_features)\n",
    "    img_labels = np.array(img_labels)\n",
    "    \n",
    "    # Reshape the fused features to have two dimensions\n",
    "    # fused_features = fused_features.reshape(-1, fused_features.shape[2])\n",
    "    fused_features = fused_features.reshape(fused_features.shape[0], -1)\n",
    " \n",
    "    # Normalize the feature vectors\n",
    "    scaler = StandardScaler()\n",
    "    fused_features = scaler.fit_transform(fused_features)\n",
    "\n",
    "    # Handle missing values with an imputer transformer\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    fused_features = imputer.fit_transform(fused_features)\n",
    "\n",
    "    # Split the fused features data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(fused_features, img_labels, test_size=0.24, random_state=31)\n",
    "\n",
    "    # Create an SVM classifier\n",
    "    # instantiate classifier with linear kernel and C=100\n",
    "    svc = svm.SVC(kernel='linear', C=100)\n",
    "\n",
    "    # Train the classifier\n",
    "    svc.fit(X_train, y_train)\n",
    "\n",
    "    # Predict labels for the test set\n",
    "    y_pred = svc.predict(X_test)\n",
    "    # print(y_pred)\n",
    "    # print(\"< ---------------- >\")\n",
    "    # print(y_test)\n",
    "    # print(\"< ---------------- >\")\n",
    "    # print(X_train)\n",
    "    # print(\"< ---------------- >\")\n",
    "    # print(X_test)\n",
    "\n",
    "    # Evaluate the classifier's performance\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='macro', zero_division=1)\n",
    "    recall = recall_score(y_test, y_pred, average='macro', zero_division=1)\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    print(\" 3_without_orb_algo algorithm \")\n",
    "    # Print the evaluation metrics\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F1 Score:\", f1)\n",
    "\n",
    "   \n",
    "    joblib.dump(svc, f\"test_3_without_orb_algo_zscore_on_ck_svm_classifier_{source_data_label}.joblib\")\n",
    "    # joblib.dump(svc, f\"lbp_zscore_on_ck_svm_classifier_{source_data_label}.joblib\")\n",
    "    # joblib.dump(svc, f\"hog_on_ck_svm_classifier_{source_data_label}.joblib\")\n",
    "    # joblib.dump(svc, f\"sift_on_ck_svm_classifier_{source_data_label}.joblib\")\n",
    "\n",
    "file_looper_transformer_extract_features_and_train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b1fbf870-db4c-4250-8aa9-ebefbb651950",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2_without_orb_sift_algo algorithm \n",
      "Accuracy: 0.9957627118644068\n",
      "Precision: 0.9968253968253968\n",
      "Recall: 0.9955357142857143\n",
      "F1 Score: 0.9961272898672577\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from operator import le\n",
    "import cv2\n",
    "import dlib\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from imutils import face_utils\n",
    "from skimage.feature import hog, local_binary_pattern\n",
    "import mahotas as mh\n",
    "import joblib\n",
    "from sklearn import svm\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import imgaug.augmenters as iaa\n",
    "\n",
    "# Resize descriptors to a consistent length\n",
    "desired_length = 1000\n",
    "# Initialize the label variable\n",
    "img_label = []\n",
    "feature_descriptors_fused = []\n",
    "\n",
    "\n",
    "def file_looper_transformer_extract_features_and_train():\n",
    "    source_data_label = \"\"\n",
    "    augmentation_seq = iaa.Sequential([\n",
    "        # iaa.Affine(rotate=(0, 10)),  # Rotate images by -10 to +10 degrees\n",
    "        iaa.Multiply((0.8, 1.0)),  # Multiply pixel values by a factor between 0.8 and 1.2\n",
    "        # iaa.GammaContrast(gamma=(0.8, 1.2)),  # Adjust gamma contrast between 0.8 and 1.2\n",
    "        # iaa.ElasticTransformation(alpha=50, sigma=5)  # Apply elastic transformations\n",
    "        # iaa.Fliplr(),  # Flip images horizontally with a 50% chance\n",
    "        # iaa.Multiply((0.8, 1.2)),  # Multiply pixel values by a factor between 0.8 and 1.2\n",
    "        # iaa.GammaContrast(),  # Adjust gamma contrast between 0.8 and 1.2\n",
    "        # iaa.ElasticTransformation(alpha=50, sigma=5)  # Apply elastic transformations\n",
    "        # iaa.Affine(rotate=(0, 10)),  # Rotate images by -10 to +10 degrees\n",
    "        # iaa.GaussianBlur(sigma=(0, 1.0)),  # Apply Gaussian blur with a sigma between 0 and 1.0\n",
    "        # iaa.AdditiveGaussianNoise(scale=(0, 0.05*255)),  # Add Gaussian noise with a scale of 0 to 0.05*255\n",
    "    ])\n",
    "    for dirname, _, filenames in os.walk('./ck'):\n",
    "        for filename in filenames:\n",
    "            # print(os.path.join(dirname, filename))\n",
    "            img_name, img_extention = os.path.splitext(filename)\n",
    "            expression_label = (os.path.join(dirname, filename)).split(os.sep)[2]\n",
    "            if source_data_label == '':\n",
    "                source_data_label = (os.path.join(dirname, filename)).split(os.sep)[1]\n",
    "\n",
    "            if(img_extention == \".jpg\" or img_extention == \".png\"):\n",
    "                image = cv2.imread(os.path.join(dirname, filename))\n",
    "                # Apply data augmentation\n",
    "                image = augmentation_seq(image=image)\n",
    "                \n",
    "                ext_feature, the_label = face_detection_extraction(image, expression_label)\n",
    "                feature_descriptors_fused.append(ext_feature)\n",
    "                img_label.append(expression_label)\n",
    "\n",
    "\n",
    "    # return feature_descriptors_fused, img_label\n",
    "    svmc(feature_descriptors_fused, img_label, source_data_label)\n",
    "\n",
    "\n",
    "def face_detection_extraction(image, image_label):\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = detector(gray, 1)\n",
    "    feature_list = []  # List to store the extracted features\n",
    "    label_list = []  # List to store the corresponding labels\n",
    "\n",
    "    for face in faces:\n",
    "        landmarks = predictor(gray, face)\n",
    "        x, y, w, h = face.left(), face.top(), face.width(), face.height()\n",
    "        extracted_face = image[y:y+h, x:x+w]\n",
    "        extracted_face = np.array(extracted_face)\n",
    "\n",
    "        shape = face_utils.shape_to_np(landmarks)\n",
    "        # Draw on our image, all the found 68 coordinate points (x,y)\n",
    "        for (x, y) in shape:\n",
    "            cv2.circle(image, (x, y), 2, (0, 255, 0), -1)\n",
    "        weight1 = 0.9  # Weight for descriptors lbp\n",
    "        weight2 = 0.9  # Weight for descriptors hog\n",
    "        weight3 = 0.2  # Weight for descriptors orb\n",
    "        weight4 = 0.2  # Weight for descriptors sift\n",
    "            \n",
    "        hog_descriptors = hog_extraction(extracted_face)\n",
    "        try:  \n",
    "            # Calculate the Z-scores for each descriptor\n",
    "            zscore_hog_descriptors = (hog_descriptors - np.mean(hog_descriptors)) / np.std(hog_descriptors)\n",
    "            # Fusion using weighted sum\n",
    "            hog_descriptors = weight2 * zscore_hog_descriptors   \n",
    "        except Exception as e:\n",
    "            # print(str(e), np.std(hog_descriptors))\n",
    "            pass    \n",
    "        hog_descriptors = np.resize(hog_descriptors, (desired_length,))\n",
    "\n",
    "        lbp_descriptors = lbp_extraction(extracted_face)\n",
    "        # Calculate the Z-scores for each descriptor\n",
    "        zscore_lbp_descriptors = (lbp_descriptors - np.mean(lbp_descriptors)) / np.std(lbp_descriptors)\n",
    "        # Fusion using weighted sum\n",
    "        lbp_descriptors = weight1 * zscore_lbp_descriptors \n",
    "        lbp_descriptors = np.resize(lbp_descriptors, (desired_length,))\n",
    "\n",
    "        orb_descriptors = orb_extraction(extracted_face)\n",
    "        # Calculate the Z-scores for each descriptor\n",
    "        # print(\" >>>\", np.std(orb_descriptors))\n",
    "        # print(\" <  > \", orb_descriptors - np.mean(orb_descriptors) )\n",
    "        try:\n",
    "            zscore_orb_descriptors = (orb_descriptors - np.mean(orb_descriptors)) / np.std(orb_descriptors)\n",
    "            # Fusion using weighted sum\n",
    "            orb_descriptors = weight3 * zscore_orb_descriptors \n",
    "            # print(\"orb_descriptors \", orb_descriptors)\n",
    "        except Exception as e:\n",
    "            # print(str(e))\n",
    "            pass\n",
    "        orb_descriptors = np.resize(orb_descriptors, (desired_length,))\n",
    "\n",
    "        sift_descriptors = sift_extraction(extracted_face)\n",
    "        try:\n",
    "            # Calculate the Z-scores for each descriptor\n",
    "            zscore_sift_descriptors = (sift_descriptors - np.mean(sift_descriptors)) / np.std(sift_descriptors)\n",
    "            # Fusion using weighted sum\n",
    "            sift_descriptors = weight4 * zscore_sift_descriptors   \n",
    "        except Exception as e:\n",
    "            # print(str(e))\n",
    "            pass    \n",
    "        sift_descriptors = np.resize(sift_descriptors, (desired_length,))\n",
    "\n",
    "        # fused_features = lbp_descriptors + hog_descriptors + sift_descriptors\n",
    "        fused_features = hog_descriptors\n",
    "        if lbp_descriptors is not None:\n",
    "            fused_features += lbp_descriptors\n",
    "        # if sift_descriptors is not None:\n",
    "        #     fused_features += sift_descriptors.astype(np.float64)\n",
    "\n",
    "        # fused_features = np.concatenate((hog_descriptors, lbp_descriptors, sift_descriptors))\n",
    "\n",
    "        if len(fused_features) > 0:\n",
    "            feature_list.append(fused_features)\n",
    "            label_list.append(image_label)  # Add the label to the list\n",
    "\n",
    "    return feature_list, label_list\n",
    "\n",
    "        # print(fused_features)\n",
    "        \n",
    "        # Display the extracted faces\n",
    "        # cv2.imshow(\"Landmark localization\", extracted_face)\n",
    "        # plt.imshow(pixels)\n",
    "        # plt.axis('off')\n",
    "        # plt.show()\n",
    "\n",
    "def hog_extraction(extracted_face):\n",
    "    # Convert the image to grayscale\n",
    "    image_gray = cv2.cvtColor(extracted_face, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Define HOG parameters\n",
    "    orientations = 9  # Number of gradient orientations\n",
    "    pixels_per_cell = (8, 8)  # Cell size in pixels\n",
    "    cells_per_block = (2, 2)  # Number of cells in each block\n",
    "\n",
    "    # Compute HOG features\n",
    "    hog_image, hog_features = hog(image_gray, orientations=orientations, pixels_per_cell=pixels_per_cell, cells_per_block=cells_per_block, visualize=True)    \n",
    "    # print(hog_features)\n",
    "    disply_feature(\"HOG\", hog_features)\n",
    "    return hog_features\n",
    "\n",
    "def lbp_extraction(extracted_face):\n",
    "    # Compute LBP features\n",
    "\n",
    "    # Get the dimensions of the image\n",
    "    # height, width, channels = extracted_face.shape\n",
    "\n",
    "    # Compute LBP features\n",
    "    radius = 3\n",
    "    n_points = 8 * radius\n",
    "    # convert to 2 dimentional\n",
    "    extracted_face = cv2.cvtColor(extracted_face, cv2.COLOR_BGR2GRAY)\n",
    "    lbp_features = local_binary_pattern(extracted_face, n_points, radius, method='default')\n",
    "    # print(lbp_features)\n",
    "    disply_feature(\"LBP\", lbp_features)\n",
    "    return lbp_features\n",
    "\n",
    "# Scale-Invariant Feature Transform descriptor\n",
    "def sift_extraction(extracted_face):\n",
    "    # Create a SIFT object\n",
    "    sift = cv2.SIFT_create()\n",
    "    # Detect keypoints and compute descriptors\n",
    "    keypoints, descriptors = sift.detectAndCompute(extracted_face, None)\n",
    "    # Draw keypoints on the image\n",
    "    image_with_keypoints = cv2.drawKeypoints(extracted_face, keypoints, None)\n",
    "    # print(descriptors)\n",
    "    disply_feature(\"SIFT\", image_with_keypoints)\n",
    "    return descriptors\n",
    "\n",
    "def orb_extraction(extracted_face):\n",
    "    # Create an ORB object with custom parameters\n",
    "    orb = cv2.ORB_create(nfeatures=1000, scaleFactor=1.2, nlevels=8, edgeThreshold=15)\n",
    "    # Resize the extracted face to a larger size for better feature extraction\n",
    "    extracted_face = cv2.resize(extracted_face, (250, 250))\n",
    "    # Convert the face image to grayscale\n",
    "    extracted_face = cv2.cvtColor(extracted_face, cv2.COLOR_BGR2GRAY)\n",
    "    # Detect keypoints and compute descriptors\n",
    "    keypoints, descriptors = orb.detectAndCompute(extracted_face, None)\n",
    "    # Draw keypoints on the image\n",
    "    image_with_keypoints = cv2.drawKeypoints(extracted_face, keypoints, None, (0, 255, 0), cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "    # disply_feature(\"ORB\", image_with_keypoints)\n",
    "    return descriptors\n",
    "\n",
    "def disply_feature(features_type, features):\n",
    "    # cv2.imshow(features_type, features)\n",
    "    # # plt.imshow( features)\n",
    "    # plt.axis('off')\n",
    "    # plt.show()\n",
    "    pass\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "def svmc(fused_features, img_labels, source_data_label):\n",
    "    \n",
    "    # Create arrays to store the features and labels\n",
    "    fused_features = np.array(fused_features)\n",
    "    img_labels = np.array(img_labels)\n",
    "    \n",
    "    # Reshape the fused features to have two dimensions\n",
    "    # fused_features = fused_features.reshape(-1, fused_features.shape[2])\n",
    "    fused_features = fused_features.reshape(fused_features.shape[0], -1)\n",
    " \n",
    "    # Normalize the feature vectors\n",
    "    scaler = StandardScaler()\n",
    "    fused_features = scaler.fit_transform(fused_features)\n",
    "\n",
    "    # Handle missing values with an imputer transformer\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    fused_features = imputer.fit_transform(fused_features)\n",
    "\n",
    "    # Split the fused features data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(fused_features, img_labels, test_size=0.24, random_state=31)\n",
    "\n",
    "    # Create an SVM classifier\n",
    "    # instantiate classifier with linear kernel and C=100\n",
    "    svc = svm.SVC(kernel='linear', C=100)\n",
    "\n",
    "    # Train the classifier\n",
    "    svc.fit(X_train, y_train)\n",
    "\n",
    "    # Predict labels for the test set\n",
    "    y_pred = svc.predict(X_test)\n",
    "    # print(y_pred)\n",
    "    # print(\"< ---------------- >\")\n",
    "    # print(y_test)\n",
    "    # print(\"< ---------------- >\")\n",
    "    # print(X_train)\n",
    "    # print(\"< ---------------- >\")\n",
    "    # print(X_test)\n",
    "\n",
    "    # Evaluate the classifier's performance\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='macro', zero_division=1)\n",
    "    recall = recall_score(y_test, y_pred, average='macro', zero_division=1)\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    print(\" 2_without_orb_sift_algo algorithm \")\n",
    "    # Print the evaluation metrics\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F1 Score:\", f1)\n",
    "\n",
    "   \n",
    "    joblib.dump(svc, f\"2_without_orb_sift_algo_zscore_on_ck_svm_classifier_{source_data_label}.joblib\")\n",
    "    # joblib.dump(svc, f\"lbp_zscore_on_ck_svm_classifier_{source_data_label}.joblib\")\n",
    "    # joblib.dump(svc, f\"hog_on_ck_svm_classifier_{source_data_label}.joblib\")\n",
    "    # joblib.dump(svc, f\"sift_on_ck_svm_classifier_{source_data_label}.joblib\")\n",
    "\n",
    "file_looper_transformer_extract_features_and_train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fdbef455-1ef6-4fe0-80d9-39c6ca04570b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 3_without_orb_algo algorithm \n",
      "Accuracy: 0.9928057553956835\n",
      "Precision: 0.9947089947089947\n",
      "Recall: 0.987012987012987\n",
      "F1 Score: 0.9905018611218072\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from operator import le\n",
    "import cv2\n",
    "import dlib\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from imutils import face_utils\n",
    "from skimage.feature import hog, local_binary_pattern\n",
    "import mahotas as mh\n",
    "import joblib\n",
    "from sklearn import svm\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import imgaug.augmenters as iaa\n",
    "\n",
    "# Resize descriptors to a consistent length\n",
    "desired_length = 1000\n",
    "# Initialize the label variable\n",
    "img_label = []\n",
    "feature_descriptors_fused = []\n",
    "\n",
    "\n",
    "def file_looper_transformer_extract_features_and_train():\n",
    "    source_data_label = \"\"\n",
    "    augmentation_seq = iaa.Sequential([\n",
    "        # iaa.Affine(rotate=(0, 10)),  # Rotate images by -10 to +10 degrees\n",
    "        iaa.Multiply((0.8, 1.0)),  # Multiply pixel values by a factor between 0.8 and 1.2\n",
    "        # iaa.GammaContrast(gamma=(0.8, 1.2)),  # Adjust gamma contrast between 0.8 and 1.2\n",
    "        # iaa.ElasticTransformation(alpha=50, sigma=5)  # Apply elastic transformations\n",
    "        # iaa.Fliplr(),  # Flip images horizontally with a 50% chance\n",
    "        # iaa.Multiply((0.8, 1.2)),  # Multiply pixel values by a factor between 0.8 and 1.2\n",
    "        # iaa.GammaContrast(),  # Adjust gamma contrast between 0.8 and 1.2\n",
    "        # iaa.ElasticTransformation(alpha=50, sigma=5)  # Apply elastic transformations\n",
    "        # iaa.Affine(rotate=(0, 10)),  # Rotate images by -10 to +10 degrees\n",
    "        # iaa.GaussianBlur(sigma=(0, 1.0)),  # Apply Gaussian blur with a sigma between 0 and 1.0\n",
    "        # iaa.AdditiveGaussianNoise(scale=(0, 0.05*255)),  # Add Gaussian noise with a scale of 0 to 0.05*255\n",
    "    ])\n",
    "    for dirname, _, filenames in os.walk('./ck'):\n",
    "        for filename in filenames:\n",
    "            # print(os.path.join(dirname, filename))\n",
    "            img_name, img_extention = os.path.splitext(filename)\n",
    "            expression_label = (os.path.join(dirname, filename)).split(os.sep)[2]\n",
    "            if source_data_label == '':\n",
    "                source_data_label = (os.path.join(dirname, filename)).split(os.sep)[1]\n",
    "\n",
    "            if(img_extention == \".jpg\" or img_extention == \".png\"):\n",
    "                image = cv2.imread(os.path.join(dirname, filename))\n",
    "                # Apply data augmentation\n",
    "                image = augmentation_seq(image=image)\n",
    "                \n",
    "                ext_feature, the_label = face_detection_extraction(image, expression_label)\n",
    "                feature_descriptors_fused.append(ext_feature)\n",
    "                img_label.append(expression_label)\n",
    "\n",
    "\n",
    "    # return feature_descriptors_fused, img_label\n",
    "    svmc(feature_descriptors_fused, img_label, source_data_label)\n",
    "\n",
    "\n",
    "def face_detection_extraction(image, image_label):\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = detector(gray, 1)\n",
    "    feature_list = []  # List to store the extracted features\n",
    "    label_list = []  # List to store the corresponding labels\n",
    "\n",
    "    for face in faces:\n",
    "        landmarks = predictor(gray, face)\n",
    "        x, y, w, h = face.left(), face.top(), face.width(), face.height()\n",
    "        extracted_face = image[y:y+h, x:x+w]\n",
    "        extracted_face = np.array(extracted_face)\n",
    "\n",
    "        shape = face_utils.shape_to_np(landmarks)\n",
    "        # Draw on our image, all the found 68 coordinate points (x,y)\n",
    "        for (x, y) in shape:\n",
    "            cv2.circle(image, (x, y), 2, (0, 255, 0), -1)\n",
    "        weight1 = 0.9  # Weight for descriptors lbp\n",
    "        weight2 = 0.9  # Weight for descriptors hog\n",
    "        weight3 = 0.2  # Weight for descriptors orb\n",
    "        weight4 = 0.2  # Weight for descriptors sift\n",
    "            \n",
    "        hog_descriptors = hog_extraction(extracted_face)\n",
    "        try:  \n",
    "            # Calculate the Z-scores for each descriptor\n",
    "            zscore_hog_descriptors = (hog_descriptors - np.mean(hog_descriptors)) / np.std(hog_descriptors)\n",
    "            # Fusion using weighted sum\n",
    "            hog_descriptors = weight2 * zscore_hog_descriptors   \n",
    "        except Exception as e:\n",
    "            # print(str(e), np.std(hog_descriptors))\n",
    "            pass    \n",
    "        hog_descriptors = np.resize(hog_descriptors, (desired_length,))\n",
    "\n",
    "        lbp_descriptors = lbp_extraction(extracted_face)\n",
    "        # Calculate the Z-scores for each descriptor\n",
    "        zscore_lbp_descriptors = (lbp_descriptors - np.mean(lbp_descriptors)) / np.std(lbp_descriptors)\n",
    "        # Fusion using weighted sum\n",
    "        lbp_descriptors = weight1 * zscore_lbp_descriptors \n",
    "        lbp_descriptors = np.resize(lbp_descriptors, (desired_length,))\n",
    "\n",
    "        orb_descriptors = orb_extraction(extracted_face)\n",
    "        # Calculate the Z-scores for each descriptor\n",
    "        # print(\" >>>\", np.std(orb_descriptors))\n",
    "        # print(\" <  > \", orb_descriptors - np.mean(orb_descriptors) )\n",
    "        try:\n",
    "            zscore_orb_descriptors = (orb_descriptors - np.mean(orb_descriptors)) / np.std(orb_descriptors)\n",
    "            # Fusion using weighted sum\n",
    "            orb_descriptors = weight3 * zscore_orb_descriptors \n",
    "            # print(\"orb_descriptors \", orb_descriptors)\n",
    "        except Exception as e:\n",
    "            # print(str(e))\n",
    "            pass\n",
    "        orb_descriptors = np.resize(orb_descriptors, (desired_length,))\n",
    "\n",
    "        sift_descriptors = sift_extraction(extracted_face)\n",
    "        try:\n",
    "            # Calculate the Z-scores for each descriptor\n",
    "            zscore_sift_descriptors = (sift_descriptors - np.mean(sift_descriptors)) / np.std(sift_descriptors)\n",
    "            # Fusion using weighted sum\n",
    "            sift_descriptors = weight4 * zscore_sift_descriptors   \n",
    "        except Exception as e:\n",
    "            # print(str(e))\n",
    "            pass    \n",
    "        sift_descriptors = np.resize(sift_descriptors, (desired_length,))\n",
    "\n",
    "        # fused_features = lbp_descriptors + hog_descriptors + sift_descriptors\n",
    "        fused_features = hog_descriptors\n",
    "        if lbp_descriptors is not None:\n",
    "            fused_features += lbp_descriptors\n",
    "        if sift_descriptors is not None:\n",
    "            fused_features += sift_descriptors.astype(np.float64)\n",
    "\n",
    "        # fused_features = np.concatenate((hog_descriptors, lbp_descriptors, sift_descriptors))\n",
    "\n",
    "        if len(fused_features) > 0:\n",
    "            feature_list.append(fused_features)\n",
    "            label_list.append(image_label)  # Add the label to the list\n",
    "\n",
    "    return feature_list, label_list\n",
    "\n",
    "        # print(fused_features)\n",
    "        \n",
    "        # Display the extracted faces\n",
    "        # cv2.imshow(\"Landmark localization\", extracted_face)\n",
    "        # plt.imshow(pixels)\n",
    "        # plt.axis('off')\n",
    "        # plt.show()\n",
    "\n",
    "def hog_extraction(extracted_face):\n",
    "    # Convert the image to grayscale\n",
    "    image_gray = cv2.cvtColor(extracted_face, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Define HOG parameters\n",
    "    orientations = 9  # Number of gradient orientations\n",
    "    pixels_per_cell = (8, 8)  # Cell size in pixels\n",
    "    cells_per_block = (2, 2)  # Number of cells in each block\n",
    "\n",
    "    # Compute HOG features\n",
    "    hog_image, hog_features = hog(image_gray, orientations=orientations, pixels_per_cell=pixels_per_cell, cells_per_block=cells_per_block, visualize=True)    \n",
    "    # print(hog_features)\n",
    "    disply_feature(\"HOG\", hog_features)\n",
    "    return hog_features\n",
    "\n",
    "def lbp_extraction(extracted_face):\n",
    "    # Compute LBP features\n",
    "\n",
    "    # Get the dimensions of the image\n",
    "    # height, width, channels = extracted_face.shape\n",
    "\n",
    "    # Compute LBP features\n",
    "    radius = 3\n",
    "    n_points = 8 * radius\n",
    "    # convert to 2 dimentional\n",
    "    extracted_face = cv2.cvtColor(extracted_face, cv2.COLOR_BGR2GRAY)\n",
    "    lbp_features = local_binary_pattern(extracted_face, n_points, radius, method='default')\n",
    "    # print(lbp_features)\n",
    "    disply_feature(\"LBP\", lbp_features)\n",
    "    return lbp_features\n",
    "\n",
    "# Scale-Invariant Feature Transform descriptor\n",
    "def sift_extraction(extracted_face):\n",
    "    # Create a SIFT object\n",
    "    sift = cv2.SIFT_create()\n",
    "    # Detect keypoints and compute descriptors\n",
    "    keypoints, descriptors = sift.detectAndCompute(extracted_face, None)\n",
    "    # Draw keypoints on the image\n",
    "    image_with_keypoints = cv2.drawKeypoints(extracted_face, keypoints, None)\n",
    "    # print(descriptors)\n",
    "    disply_feature(\"SIFT\", image_with_keypoints)\n",
    "    return descriptors\n",
    "\n",
    "def orb_extraction(extracted_face):\n",
    "    # Create an ORB object with custom parameters\n",
    "    orb = cv2.ORB_create(nfeatures=1000, scaleFactor=1.2, nlevels=8, edgeThreshold=15)\n",
    "    # Resize the extracted face to a larger size for better feature extraction\n",
    "    extracted_face = cv2.resize(extracted_face, (250, 250))\n",
    "    # Convert the face image to grayscale\n",
    "    extracted_face = cv2.cvtColor(extracted_face, cv2.COLOR_BGR2GRAY)\n",
    "    # Detect keypoints and compute descriptors\n",
    "    keypoints, descriptors = orb.detectAndCompute(extracted_face, None)\n",
    "    # Draw keypoints on the image\n",
    "    image_with_keypoints = cv2.drawKeypoints(extracted_face, keypoints, None, (0, 255, 0), cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "    # disply_feature(\"ORB\", image_with_keypoints)\n",
    "    return descriptors\n",
    "\n",
    "def disply_feature(features_type, features):\n",
    "    # cv2.imshow(features_type, features)\n",
    "    # # plt.imshow( features)\n",
    "    # plt.axis('off')\n",
    "    # plt.show()\n",
    "    pass\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "def svmc(fused_features, img_labels, source_data_label):\n",
    "    \n",
    "    # Create arrays to store the features and labels\n",
    "    fused_features = np.array(fused_features)\n",
    "    img_labels = np.array(img_labels)\n",
    "    \n",
    "    # Reshape the fused features to have two dimensions\n",
    "    # fused_features = fused_features.reshape(-1, fused_features.shape[2])\n",
    "    fused_features = fused_features.reshape(fused_features.shape[0], -1)\n",
    " \n",
    "    # Normalize the feature vectors\n",
    "    scaler = StandardScaler()\n",
    "    fused_features = scaler.fit_transform(fused_features)\n",
    "\n",
    "    # Handle missing values with an imputer transformer\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    fused_features = imputer.fit_transform(fused_features)\n",
    "\n",
    "    # Split the fused features data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(fused_features, img_labels, test_size=0.1412, random_state=44)\n",
    "\n",
    "    # Create an SVM classifier\n",
    "    # instantiate classifier with linear kernel and C=100\n",
    "    svc = svm.SVC(kernel='linear', C=100)\n",
    "\n",
    "    # Train the classifier\n",
    "    svc.fit(X_train, y_train)\n",
    "\n",
    "    # Predict labels for the test set\n",
    "    y_pred = svc.predict(X_test)\n",
    "    # print(y_pred)\n",
    "    # print(\"< ---------------- >\")\n",
    "    # print(y_test)\n",
    "    # print(\"< ---------------- >\")\n",
    "    # print(X_train)\n",
    "    # print(\"< ---------------- >\")\n",
    "    # print(X_test)\n",
    "\n",
    "    # Evaluate the classifier's performance\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='macro', zero_division=1)\n",
    "    recall = recall_score(y_test, y_pred, average='macro', zero_division=1)\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    print(\" 3_without_orb_algo algorithm \")\n",
    "    # Print the evaluation metrics\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F1 Score:\", f1)\n",
    "\n",
    "   \n",
    "    joblib.dump(svc, f\"3_without_orb_algo_zscore_on_ck_svm_classifier_{source_data_label}.joblib\")\n",
    "    # joblib.dump(svc, f\"lbp_zscore_on_ck_svm_classifier_{source_data_label}.joblib\")\n",
    "    # joblib.dump(svc, f\"hog_on_ck_svm_classifier_{source_data_label}.joblib\")\n",
    "    # joblib.dump(svc, f\"sift_on_ck_svm_classifier_{source_data_label}.joblib\")\n",
    "\n",
    "file_looper_transformer_extract_features_and_train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fdbab5dc-8417-461b-9611-bd6358b37a7d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " lbp_algo algorithm  jaffe\n",
      "Accuracy: 0.6666666666666666\n",
      "Precision: 0.7142857142857143\n",
      "Recall: 0.7142857142857143\n",
      "F1 Score: 0.42857142857142855\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from operator import le\n",
    "import cv2\n",
    "import dlib\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from imutils import face_utils\n",
    "from skimage.feature import hog, local_binary_pattern\n",
    "import mahotas as mh\n",
    "import joblib\n",
    "from sklearn import svm\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import imgaug.augmenters as iaa\n",
    "\n",
    "# Resize descriptors to a consistent length\n",
    "desired_length = 1000\n",
    "# Initialize the label variable\n",
    "img_label = []\n",
    "feature_descriptors_fused = []\n",
    "\n",
    "\n",
    "def file_looper_transformer_extract_features_and_train():\n",
    "    source_data_label = \"\"\n",
    "\n",
    "    for dirname, _, filenames in os.walk('./jaffe'):\n",
    "        for filename in filenames:\n",
    "            # print(os.path.join(dirname, filename))\n",
    "            img_name, img_extention = os.path.splitext(filename)\n",
    "            expression_label = (os.path.join(dirname, filename)).split(os.sep)[2]\n",
    "            if source_data_label == '':\n",
    "                source_data_label = (os.path.join(dirname, filename)).split(os.sep)[1]\n",
    "\n",
    "            if(img_extention == \".jpg\" or img_extention == \".png\"):\n",
    "                image = cv2.imread(os.path.join(dirname, filename))\n",
    "                # Apply data augmentation\n",
    "                # image = augmentation_seq(image=image)\n",
    "                \n",
    "                ext_feature, the_label = face_detection_extraction(image, expression_label)\n",
    "                feature_descriptors_fused.append(ext_feature)\n",
    "                img_label.append(expression_label)\n",
    "\n",
    "\n",
    "    # return feature_descriptors_fused, img_label\n",
    "    svmc(feature_descriptors_fused, img_label, source_data_label)\n",
    "\n",
    "\n",
    "def face_detection_extraction(image, image_label):\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = detector(gray, 1)\n",
    "    feature_list = []  # List to store the extracted features\n",
    "    label_list = []  # List to store the corresponding labels\n",
    "\n",
    "    for face in faces:\n",
    "        landmarks = predictor(gray, face)\n",
    "        x, y, w, h = face.left(), face.top(), face.width(), face.height()\n",
    "        extracted_face = image[y:y+h, x:x+w]\n",
    "        extracted_face = np.array(extracted_face)\n",
    "\n",
    "        shape = face_utils.shape_to_np(landmarks)\n",
    "        # Draw on our image, all the found 68 coordinate points (x,y)\n",
    "        for (x, y) in shape:\n",
    "            cv2.circle(image, (x, y), 2, (0, 255, 0), -1)\n",
    "        weight1 = 0.9  # Weight for descriptors lbp\n",
    "        weight2 = 0.9  # Weight for descriptors hog\n",
    "        weight3 = 0.2  # Weight for descriptors orb\n",
    "        weight4 = 0.2  # Weight for descriptors sift\n",
    "            \n",
    "\n",
    "        lbp_descriptors = lbp_extraction(extracted_face)\n",
    "        # Calculate the Z-scores for each descriptor\n",
    "        zscore_lbp_descriptors = (lbp_descriptors - np.mean(lbp_descriptors)) / np.std(lbp_descriptors)\n",
    "        # Fusion using weighted sum\n",
    "        lbp_descriptors = weight1 * zscore_lbp_descriptors \n",
    "        lbp_descriptors = np.resize(lbp_descriptors, (desired_length,))\n",
    "\n",
    "\n",
    "        # fused_features = lbp_descriptors + hog_descriptors + sift_descriptors\n",
    "        fused_features = lbp_descriptors\n",
    "        # if lbp_descriptors is not None:\n",
    "        #     fused_features += lbp_descriptors\n",
    "\n",
    "        # fused_features = np.concatenate((hog_descriptors, lbp_descriptors, sift_descriptors))\n",
    "\n",
    "        if len(fused_features) > 0:\n",
    "            feature_list.append(fused_features)\n",
    "            label_list.append(image_label)  # Add the label to the list\n",
    "\n",
    "    return feature_list, label_list\n",
    "\n",
    "        # print(fused_features)\n",
    "        \n",
    "        # Display the extracted faces\n",
    "        # cv2.imshow(\"Landmark localization\", extracted_face)\n",
    "        # plt.imshow(pixels)\n",
    "        # plt.axis('off')\n",
    "        # plt.show()\n",
    "\n",
    "def lbp_extraction(extracted_face):\n",
    "    # Compute LBP features\n",
    "\n",
    "    # Get the dimensions of the image\n",
    "    # height, width, channels = extracted_face.shape\n",
    "\n",
    "    # Compute LBP features\n",
    "    radius = 3\n",
    "    n_points = 8 * radius\n",
    "    # convert to 2 dimentional\n",
    "    extracted_face = cv2.cvtColor(extracted_face, cv2.COLOR_BGR2GRAY)\n",
    "    lbp_features = local_binary_pattern(extracted_face, n_points, radius, method='default')\n",
    "    # print(lbp_features)\n",
    "    disply_feature(\"LBP\", lbp_features)\n",
    "    return lbp_features\n",
    "\n",
    "def disply_feature(features_type, features):\n",
    "    # cv2.imshow(features_type, features)\n",
    "    # # plt.imshow( features)\n",
    "    # plt.axis('off')\n",
    "    # plt.show()\n",
    "    pass\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "def svmc(fused_features, img_labels, source_data_label):\n",
    "    \n",
    "    # Create arrays to store the features and labels\n",
    "    fused_features = np.array(fused_features)\n",
    "    img_labels = np.array(img_labels)\n",
    "    \n",
    "    # Reshape the fused features to have two dimensions\n",
    "    # fused_features = fused_features.reshape(-1, fused_features.shape[2])\n",
    "    fused_features = fused_features.reshape(fused_features.shape[0], -1)\n",
    " \n",
    "    # Normalize the feature vectors\n",
    "    scaler = StandardScaler()\n",
    "    fused_features = scaler.fit_transform(fused_features)\n",
    "\n",
    "    # Handle missing values with an imputer transformer\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    fused_features = imputer.fit_transform(fused_features)\n",
    "\n",
    "    # Split the fused features data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(fused_features, img_labels, test_size=0.024, random_state=44)\n",
    "\n",
    "    # Create an SVM classifier\n",
    "    # instantiate classifier with linear kernel and C=100\n",
    "    svc = svm.SVC(kernel='linear', C=100)\n",
    "\n",
    "    # Train the classifier\n",
    "    svc.fit(X_train, y_train)\n",
    "\n",
    "    # Predict labels for the test set\n",
    "    y_pred = svc.predict(X_test)\n",
    "    # print(y_pred)\n",
    "    # print(\"< ---------------- >\")\n",
    "    # print(y_test)\n",
    "    # print(\"< ---------------- >\")\n",
    "    # print(X_train)\n",
    "    # print(\"< ---------------- >\")\n",
    "    # print(X_test)\n",
    "\n",
    "    # Evaluate the classifier's performance\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='macro', zero_division=1)\n",
    "    recall = recall_score(y_test, y_pred, average='macro', zero_division=1)\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    print(\" lbp_algo algorithm \", source_data_label)\n",
    "    # Print the evaluation metrics\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F1 Score:\", f1)\n",
    "\n",
    "   \n",
    "    joblib.dump(svc, f\"lbp_algo_zscore_on_svm_classifier_{source_data_label}.joblib\")\n",
    "    # joblib.dump(svc, f\"lbp_zscore_on_svm_classifier_{source_data_label}.joblib\")\n",
    "    # joblib.dump(svc, f\"hog_on_svm_classifier_{source_data_label}.joblib\")\n",
    "    # joblib.dump(svc, f\"sift_on_svm_classifier_{source_data_label}.joblib\")\n",
    "\n",
    "file_looper_transformer_extract_features_and_train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "09cf3346-9a7f-418f-b80a-fc07f6fdbd51",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sift_algo algorithm  jaffe\n",
      "Accuracy: 0.3333333333333333\n",
      "Precision: 0.5\n",
      "Recall: 0.5714285714285714\n",
      "F1 Score: 0.23809523809523808\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from operator import le\n",
    "import cv2\n",
    "import dlib\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from imutils import face_utils\n",
    "from skimage.feature import hog, local_binary_pattern\n",
    "import mahotas as mh\n",
    "import joblib\n",
    "from sklearn import svm\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import imgaug.augmenters as iaa\n",
    "\n",
    "# Resize descriptors to a consistent length\n",
    "desired_length = 1000\n",
    "# Initialize the label variable\n",
    "img_label = []\n",
    "feature_descriptors_fused = []\n",
    "\n",
    "\n",
    "def file_looper_transformer_extract_features_and_train():\n",
    "    source_data_label = \"\"\n",
    "\n",
    "    for dirname, _, filenames in os.walk('./jaffe'):\n",
    "        for filename in filenames:\n",
    "            # print(os.path.join(dirname, filename))\n",
    "            img_name, img_extention = os.path.splitext(filename)\n",
    "            expression_label = (os.path.join(dirname, filename)).split(os.sep)[2]\n",
    "            if source_data_label == '':\n",
    "                source_data_label = (os.path.join(dirname, filename)).split(os.sep)[1]\n",
    "\n",
    "            if(img_extention == \".jpg\" or img_extention == \".png\"):\n",
    "                image = cv2.imread(os.path.join(dirname, filename))\n",
    "                # Apply data augmentation\n",
    "                # image = augmentation_seq(image=image)\n",
    "                \n",
    "                ext_feature, the_label = face_detection_extraction(image, expression_label)\n",
    "                feature_descriptors_fused.append(ext_feature)\n",
    "                img_label.append(expression_label)\n",
    "\n",
    "\n",
    "    # return feature_descriptors_fused, img_label\n",
    "    svmc(feature_descriptors_fused, img_label, source_data_label)\n",
    "\n",
    "\n",
    "def face_detection_extraction(image, image_label):\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = detector(gray, 1)\n",
    "    feature_list = []  # List to store the extracted features\n",
    "    label_list = []  # List to store the corresponding labels\n",
    "\n",
    "    for face in faces:\n",
    "        landmarks = predictor(gray, face)\n",
    "        x, y, w, h = face.left(), face.top(), face.width(), face.height()\n",
    "        extracted_face = image[y:y+h, x:x+w]\n",
    "        extracted_face = np.array(extracted_face)\n",
    "\n",
    "        shape = face_utils.shape_to_np(landmarks)\n",
    "        # Draw on our image, all the found 68 coordinate points (x,y)\n",
    "        for (x, y) in shape:\n",
    "            cv2.circle(image, (x, y), 2, (0, 255, 0), -1)\n",
    "        weight1 = 0.9  # Weight for descriptors lbp\n",
    "        weight2 = 0.9  # Weight for descriptors hog\n",
    "        weight3 = 0.2  # Weight for descriptors orb\n",
    "        weight4 = 0.2  # Weight for descriptors sift\n",
    "            \n",
    "\n",
    "        sift_descriptors = sift_extraction(extracted_face)\n",
    "        try:\n",
    "            # Calculate the Z-scores for each descriptor\n",
    "            zscore_sift_descriptors = (sift_descriptors - np.mean(sift_descriptors)) / np.std(sift_descriptors)\n",
    "            # Fusion using weighted sum\n",
    "            sift_descriptors = weight4 * zscore_sift_descriptors   \n",
    "        except Exception as e:\n",
    "            # print(str(e))\n",
    "            pass    \n",
    "        sift_descriptors = np.resize(sift_descriptors, (desired_length,))\n",
    "\n",
    "        # fused_features = lbp_descriptors + hog_descriptors + sift_descriptors\n",
    "        fused_features = sift_descriptors\n",
    "\n",
    "        # fused_features = np.concatenate((hog_descriptors, lbp_descriptors, sift_descriptors))\n",
    "\n",
    "        if len(fused_features) > 0:\n",
    "            feature_list.append(fused_features)\n",
    "            label_list.append(image_label)  # Add the label to the list\n",
    "\n",
    "    return feature_list, label_list\n",
    "\n",
    "        # print(fused_features)\n",
    "        \n",
    "        # Display the extracted faces\n",
    "        # cv2.imshow(\"Landmark localization\", extracted_face)\n",
    "        # plt.imshow(pixels)\n",
    "        # plt.axis('off')\n",
    "        # plt.show()\n",
    "\n",
    "# Scale-Invariant Feature Transform descriptor\n",
    "def sift_extraction(extracted_face):\n",
    "    # Create a SIFT object\n",
    "    sift = cv2.SIFT_create()\n",
    "    # Detect keypoints and compute descriptors\n",
    "    keypoints, descriptors = sift.detectAndCompute(extracted_face, None)\n",
    "    # Draw keypoints on the image\n",
    "    image_with_keypoints = cv2.drawKeypoints(extracted_face, keypoints, None)\n",
    "    # print(descriptors)\n",
    "    disply_feature(\"SIFT\", image_with_keypoints)\n",
    "    return descriptors\n",
    "\n",
    "def disply_feature(features_type, features):\n",
    "    # cv2.imshow(features_type, features)\n",
    "    # # plt.imshow( features)\n",
    "    # plt.axis('off')\n",
    "    # plt.show()\n",
    "    pass\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "def svmc(fused_features, img_labels, source_data_label):\n",
    "    \n",
    "    # Create arrays to store the features and labels\n",
    "    fused_features = np.array(fused_features)\n",
    "    img_labels = np.array(img_labels)\n",
    "    \n",
    "    # Reshape the fused features to have two dimensions\n",
    "    # fused_features = fused_features.reshape(-1, fused_features.shape[2])\n",
    "    fused_features = fused_features.reshape(fused_features.shape[0], -1)\n",
    " \n",
    "    # Normalize the feature vectors\n",
    "    scaler = StandardScaler()\n",
    "    fused_features = scaler.fit_transform(fused_features)\n",
    "\n",
    "    # Handle missing values with an imputer transformer\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    fused_features = imputer.fit_transform(fused_features)\n",
    "\n",
    "    # Split the fused features data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(fused_features, img_labels, test_size=0.024, random_state=44)\n",
    "\n",
    "    # Create an SVM classifier\n",
    "    # instantiate classifier with linear kernel and C=100\n",
    "    svc = svm.SVC(kernel='linear', C=100)\n",
    "\n",
    "    # Train the classifier\n",
    "    svc.fit(X_train, y_train)\n",
    "\n",
    "    # Predict labels for the test set\n",
    "    y_pred = svc.predict(X_test)\n",
    "    # print(y_pred)\n",
    "    # print(\"< ---------------- >\")\n",
    "    # print(y_test)\n",
    "    # print(\"< ---------------- >\")\n",
    "    # print(X_train)\n",
    "    # print(\"< ---------------- >\")\n",
    "    # print(X_test)\n",
    "\n",
    "    # Evaluate the classifier's performance\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='macro', zero_division=1)\n",
    "    recall = recall_score(y_test, y_pred, average='macro', zero_division=1)\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    print(\"sift_algo algorithm \", source_data_label)\n",
    "    # Print the evaluation metrics\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F1 Score:\", f1)\n",
    "\n",
    "   \n",
    "    joblib.dump(svc, f\"sift_algo_zscore_on_svm_classifier_{source_data_label}.joblib\")\n",
    "    # joblib.dump(svc, f\"lbp_zscore_on_svm_classifier_{source_data_label}.joblib\")\n",
    "    # joblib.dump(svc, f\"hog_on_svm_classifier_{source_data_label}.joblib\")\n",
    "    # joblib.dump(svc, f\"sift_on_svm_classifier_{source_data_label}.joblib\")\n",
    "\n",
    "file_looper_transformer_extract_features_and_train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5a899198-ab4d-478e-a47a-d7140bc5d26b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orb_algo algorithm  jaffe\n",
      "Accuracy: 0.16666666666666666\n",
      "Precision: 0.5\n",
      "Recall: 0.35714285714285715\n",
      "F1 Score: 0.07142857142857142\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from operator import le\n",
    "import cv2\n",
    "import dlib\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from imutils import face_utils\n",
    "from skimage.feature import hog, local_binary_pattern\n",
    "import mahotas as mh\n",
    "import joblib\n",
    "from sklearn import svm\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import imgaug.augmenters as iaa\n",
    "\n",
    "# Resize descriptors to a consistent length\n",
    "desired_length = 1000\n",
    "# Initialize the label variable\n",
    "img_label = []\n",
    "feature_descriptors_fused = []\n",
    "\n",
    "\n",
    "def file_looper_transformer_extract_features_and_train():\n",
    "    source_data_label = \"\"\n",
    "\n",
    "    for dirname, _, filenames in os.walk('./jaffe'):\n",
    "        for filename in filenames:\n",
    "            # print(os.path.join(dirname, filename))\n",
    "            img_name, img_extention = os.path.splitext(filename)\n",
    "            expression_label = (os.path.join(dirname, filename)).split(os.sep)[2]\n",
    "            if source_data_label == '':\n",
    "                source_data_label = (os.path.join(dirname, filename)).split(os.sep)[1]\n",
    "\n",
    "            if(img_extention == \".jpg\" or img_extention == \".png\"):\n",
    "                image = cv2.imread(os.path.join(dirname, filename))\n",
    "                # Apply data augmentation\n",
    "                # image = augmentation_seq(image=image)\n",
    "                \n",
    "                ext_feature, the_label = face_detection_extraction(image, expression_label)\n",
    "                feature_descriptors_fused.append(ext_feature)\n",
    "                img_label.append(expression_label)\n",
    "\n",
    "\n",
    "    # return feature_descriptors_fused, img_label\n",
    "    svmc(feature_descriptors_fused, img_label, source_data_label)\n",
    "\n",
    "\n",
    "def face_detection_extraction(image, image_label):\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = detector(gray, 1)\n",
    "    feature_list = []  # List to store the extracted features\n",
    "    label_list = []  # List to store the corresponding labels\n",
    "\n",
    "    for face in faces:\n",
    "        landmarks = predictor(gray, face)\n",
    "        x, y, w, h = face.left(), face.top(), face.width(), face.height()\n",
    "        extracted_face = image[y:y+h, x:x+w]\n",
    "        extracted_face = np.array(extracted_face)\n",
    "\n",
    "        shape = face_utils.shape_to_np(landmarks)\n",
    "        # Draw on our image, all the found 68 coordinate points (x,y)\n",
    "        for (x, y) in shape:\n",
    "            cv2.circle(image, (x, y), 2, (0, 255, 0), -1)\n",
    "        weight1 = 0.9  # Weight for descriptors lbp\n",
    "        weight2 = 0.9  # Weight for descriptors hog\n",
    "        weight3 = 0.2  # Weight for descriptors orb\n",
    "        weight4 = 0.2  # Weight for descriptors sift\n",
    "            \n",
    "        orb_descriptors = orb_extraction(extracted_face)\n",
    "        # Calculate the Z-scores for each descriptor\n",
    "        # print(\" >>>\", np.std(orb_descriptors))\n",
    "        # print(\" <  > \", orb_descriptors - np.mean(orb_descriptors) )\n",
    "        try:\n",
    "            zscore_orb_descriptors = (orb_descriptors - np.mean(orb_descriptors)) / np.std(orb_descriptors)\n",
    "            # Fusion using weighted sum\n",
    "            orb_descriptors = weight3 * zscore_orb_descriptors \n",
    "            # print(\"orb_descriptors \", orb_descriptors)\n",
    "        except Exception as e:\n",
    "            # print(str(e))\n",
    "            pass\n",
    "        orb_descriptors = np.resize(orb_descriptors, (desired_length,))\n",
    "\n",
    "        fused_features = orb_descriptors\n",
    "        # if orb_descriptors is not None:\n",
    "        #     fused_features += orb_descriptors.astype(np.float64)\n",
    "\n",
    "        # fused_features = np.concatenate((hog_descriptors, lbp_descriptors, sift_descriptors))\n",
    "\n",
    "        if len(fused_features) > 0:\n",
    "            feature_list.append(fused_features)\n",
    "            label_list.append(image_label)  # Add the label to the list\n",
    "\n",
    "    return feature_list, label_list\n",
    "\n",
    "        # print(fused_features)\n",
    "        \n",
    "        # Display the extracted faces\n",
    "        # cv2.imshow(\"Landmark localization\", extracted_face)\n",
    "        # plt.imshow(pixels)\n",
    "        # plt.axis('off')\n",
    "        # plt.show()\n",
    "\n",
    "def orb_extraction(extracted_face):\n",
    "    # Create an ORB object with custom parameters\n",
    "    orb = cv2.ORB_create(nfeatures=1000, scaleFactor=1.2, nlevels=8, edgeThreshold=15)\n",
    "    # Resize the extracted face to a larger size for better feature extraction\n",
    "    extracted_face = cv2.resize(extracted_face, (250, 250))\n",
    "    # Convert the face image to grayscale\n",
    "    extracted_face = cv2.cvtColor(extracted_face, cv2.COLOR_BGR2GRAY)\n",
    "    # Detect keypoints and compute descriptors\n",
    "    keypoints, descriptors = orb.detectAndCompute(extracted_face, None)\n",
    "    # Draw keypoints on the image\n",
    "    image_with_keypoints = cv2.drawKeypoints(extracted_face, keypoints, None, (0, 255, 0), cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "    # disply_feature(\"ORB\", image_with_keypoints)\n",
    "    return descriptors\n",
    "\n",
    "def disply_feature(features_type, features):\n",
    "    # cv2.imshow(features_type, features)\n",
    "    # # plt.imshow( features)\n",
    "    # plt.axis('off')\n",
    "    # plt.show()\n",
    "    pass\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "def svmc(fused_features, img_labels, source_data_label):\n",
    "    \n",
    "    # Create arrays to store the features and labels\n",
    "    fused_features = np.array(fused_features)\n",
    "    img_labels = np.array(img_labels)\n",
    "    \n",
    "    # Reshape the fused features to have two dimensions\n",
    "    # fused_features = fused_features.reshape(-1, fused_features.shape[2])\n",
    "    fused_features = fused_features.reshape(fused_features.shape[0], -1)\n",
    " \n",
    "    # Normalize the feature vectors\n",
    "    scaler = StandardScaler()\n",
    "    fused_features = scaler.fit_transform(fused_features)\n",
    "\n",
    "    # Handle missing values with an imputer transformer\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    fused_features = imputer.fit_transform(fused_features)\n",
    "\n",
    "    # Split the fused features data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(fused_features, img_labels, test_size=0.024, random_state=44)\n",
    "\n",
    "    # Create an SVM classifier\n",
    "    # instantiate classifier with linear kernel and C=100\n",
    "    svc = svm.SVC(kernel='linear', C=100)\n",
    "\n",
    "    # Train the classifier\n",
    "    svc.fit(X_train, y_train)\n",
    "\n",
    "    # Predict labels for the test set\n",
    "    y_pred = svc.predict(X_test)\n",
    "    # print(y_pred)\n",
    "    # print(\"< ---------------- >\")\n",
    "    # print(y_test)\n",
    "    # print(\"< ---------------- >\")\n",
    "    # print(X_train)\n",
    "    # print(\"< ---------------- >\")\n",
    "    # print(X_test)\n",
    "\n",
    "    # Evaluate the classifier's performance\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='macro', zero_division=1)\n",
    "    recall = recall_score(y_test, y_pred, average='macro', zero_division=1)\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    print(\"orb_algo algorithm \", source_data_label)\n",
    "    # Print the evaluation metrics\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F1 Score:\", f1)\n",
    "\n",
    "   \n",
    "    joblib.dump(svc, f\"orb_algo_zscore_on_svm_classifier_{source_data_label}.joblib\")\n",
    "    # joblib.dump(svc, f\"lbp_zscore_on_svm_classifier_{source_data_label}.joblib\")\n",
    "    # joblib.dump(svc, f\"hog_on_svm_classifier_{source_data_label}.joblib\")\n",
    "    # joblib.dump(svc, f\"sift_on_svm_classifier_{source_data_label}.joblib\")\n",
    "\n",
    "file_looper_transformer_extract_features_and_train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ed3d80c4-bf17-4bf5-a8da-ee2c348fecab",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hog_algo algorithm  jaffe\n",
      "Accuracy: 0.375\n",
      "Precision: 0.5\n",
      "Recall: 0.5833333333333334\n",
      "F1 Score: 0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from operator import le\n",
    "import cv2\n",
    "import dlib\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from imutils import face_utils\n",
    "from skimage.feature import hog, local_binary_pattern\n",
    "import mahotas as mh\n",
    "import joblib\n",
    "from sklearn import svm\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import imgaug.augmenters as iaa\n",
    "\n",
    "# Resize descriptors to a consistent length\n",
    "desired_length = 1000\n",
    "# Initialize the label variable\n",
    "img_label = []\n",
    "feature_descriptors_fused = []\n",
    "\n",
    "\n",
    "def file_looper_transformer_extract_features_and_train():\n",
    "    source_data_label = \"\"\n",
    "\n",
    "    for dirname, _, filenames in os.walk('./jaffe'):\n",
    "        for filename in filenames:\n",
    "            # print(os.path.join(dirname, filename))\n",
    "            img_name, img_extention = os.path.splitext(filename)\n",
    "            expression_label = (os.path.join(dirname, filename)).split(os.sep)[2]\n",
    "            if source_data_label == '':\n",
    "                source_data_label = (os.path.join(dirname, filename)).split(os.sep)[1]\n",
    "\n",
    "            if(img_extention == \".jpg\" or img_extention == \".png\"):\n",
    "                image = cv2.imread(os.path.join(dirname, filename))\n",
    "                # Apply data augmentation\n",
    "                # image = augmentation_seq(image=image)\n",
    "                \n",
    "                ext_feature, the_label = face_detection_extraction(image, expression_label)\n",
    "                feature_descriptors_fused.append(ext_feature)\n",
    "                img_label.append(expression_label)\n",
    "\n",
    "\n",
    "    # return feature_descriptors_fused, img_label\n",
    "    svmc(feature_descriptors_fused, img_label, source_data_label)\n",
    "\n",
    "\n",
    "def face_detection_extraction(image, image_label):\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = detector(gray, 1)\n",
    "    feature_list = []  # List to store the extracted features\n",
    "    label_list = []  # List to store the corresponding labels\n",
    "\n",
    "    for face in faces:\n",
    "        landmarks = predictor(gray, face)\n",
    "        x, y, w, h = face.left(), face.top(), face.width(), face.height()\n",
    "        extracted_face = image[y:y+h, x:x+w]\n",
    "        extracted_face = np.array(extracted_face)\n",
    "\n",
    "        shape = face_utils.shape_to_np(landmarks)\n",
    "        # Draw on our image, all the found 68 coordinate points (x,y)\n",
    "        for (x, y) in shape:\n",
    "            cv2.circle(image, (x, y), 2, (0, 255, 0), -1)\n",
    "        weight1 = 0.9  # Weight for descriptors lbp\n",
    "        weight2 = 0.9  # Weight for descriptors hog\n",
    "        weight3 = 0.2  # Weight for descriptors orb\n",
    "        weight4 = 0.2  # Weight for descriptors sift\n",
    "            \n",
    "        hog_descriptors = hog_extraction(extracted_face)\n",
    "        try:  \n",
    "            # Calculate the Z-scores for each descriptor\n",
    "            zscore_hog_descriptors = (hog_descriptors - np.mean(hog_descriptors)) / np.std(hog_descriptors)\n",
    "            # Fusion using weighted sum\n",
    "            hog_descriptors = weight2 * zscore_hog_descriptors   \n",
    "        except Exception as e:\n",
    "            # print(str(e), np.std(hog_descriptors))\n",
    "            pass    \n",
    "        hog_descriptors = np.resize(hog_descriptors, (desired_length,))\n",
    "\n",
    "        # fused_features = lbp_descriptors + hog_descriptors + sift_descriptors\n",
    "        fused_features = hog_descriptors\n",
    "\n",
    "        # fused_features = np.concatenate((hog_descriptors, lbp_descriptors, sift_descriptors))\n",
    "\n",
    "        if len(fused_features) > 0:\n",
    "            feature_list.append(fused_features)\n",
    "            label_list.append(image_label)  # Add the label to the list\n",
    "\n",
    "    return feature_list, label_list\n",
    "\n",
    "        # print(fused_features)\n",
    "        \n",
    "        # Display the extracted faces\n",
    "        # cv2.imshow(\"Landmark localization\", extracted_face)\n",
    "        # plt.imshow(pixels)\n",
    "        # plt.axis('off')\n",
    "        # plt.show()\n",
    "\n",
    "def hog_extraction(extracted_face):\n",
    "    # Convert the image to grayscale\n",
    "    image_gray = cv2.cvtColor(extracted_face, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Define HOG parameters\n",
    "    orientations = 9  # Number of gradient orientations\n",
    "    pixels_per_cell = (8, 8)  # Cell size in pixels\n",
    "    cells_per_block = (2, 2)  # Number of cells in each block\n",
    "\n",
    "    # Compute HOG features\n",
    "    hog_image, hog_features = hog(image_gray, orientations=orientations, pixels_per_cell=pixels_per_cell, cells_per_block=cells_per_block, visualize=True)    \n",
    "    # print(hog_features)\n",
    "    disply_feature(\"HOG\", hog_features)\n",
    "    return hog_features\n",
    "\n",
    "def disply_feature(features_type, features):\n",
    "    # cv2.imshow(features_type, features)\n",
    "    # # plt.imshow( features)\n",
    "    # plt.axis('off')\n",
    "    # plt.show()\n",
    "    pass\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "def svmc(fused_features, img_labels, source_data_label):\n",
    "    \n",
    "    # Create arrays to store the features and labels\n",
    "    fused_features = np.array(fused_features)\n",
    "    img_labels = np.array(img_labels)\n",
    "    \n",
    "    # Reshape the fused features to have two dimensions\n",
    "    # fused_features = fused_features.reshape(-1, fused_features.shape[2])\n",
    "    fused_features = fused_features.reshape(fused_features.shape[0], -1)\n",
    " \n",
    "    # Normalize the feature vectors\n",
    "    scaler = StandardScaler()\n",
    "    fused_features = scaler.fit_transform(fused_features)\n",
    "\n",
    "    # Handle missing values with an imputer transformer\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    fused_features = imputer.fit_transform(fused_features)\n",
    "\n",
    "    # Split the fused features data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(fused_features, img_labels, test_size=0.034, random_state=44)\n",
    "\n",
    "    # Create an SVM classifier\n",
    "    # instantiate classifier with linear kernel and C=100\n",
    "    svc = svm.SVC(kernel='linear', C=100)\n",
    "\n",
    "    # Train the classifier\n",
    "    svc.fit(X_train, y_train)\n",
    "\n",
    "    # Predict labels for the test set\n",
    "    y_pred = svc.predict(X_test)\n",
    "    # print(y_pred)\n",
    "    # print(\"< ---------------- >\")\n",
    "    # print(y_test)\n",
    "    # print(\"< ---------------- >\")\n",
    "    # print(X_train)\n",
    "    # print(\"< ---------------- >\")\n",
    "    # print(X_test)\n",
    "\n",
    "    # Evaluate the classifier's performance\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='macro', zero_division=1)\n",
    "    recall = recall_score(y_test, y_pred, average='macro', zero_division=1)\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    print(\"hog_algo algorithm \", source_data_label)\n",
    "    # Print the evaluation metrics\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F1 Score:\", f1)\n",
    "\n",
    "   \n",
    "    joblib.dump(svc, f\"hog_algo_zscore_on_svm_classifier_{source_data_label}.joblib\")\n",
    "    # joblib.dump(svc, f\"lbp_zscore_on_svm_classifier_{source_data_label}.joblib\")\n",
    "    # joblib.dump(svc, f\"hog_on_svm_classifier_{source_data_label}.joblib\")\n",
    "    # joblib.dump(svc, f\"sift_on_svm_classifier_{source_data_label}.joblib\")\n",
    "\n",
    "file_looper_transformer_extract_features_and_train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "33272978-03b6-4003-80c7-260e59959398",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2_without_hog_sift_algo algorithm  jaffe\n",
      "Accuracy: 0.6666666666666666\n",
      "Precision: 0.7142857142857143\n",
      "Recall: 0.7142857142857143\n",
      "F1 Score: 0.42857142857142855\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from operator import le\n",
    "import cv2\n",
    "import dlib\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from imutils import face_utils\n",
    "from skimage.feature import hog, local_binary_pattern\n",
    "import mahotas as mh\n",
    "import joblib\n",
    "from sklearn import svm\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import imgaug.augmenters as iaa\n",
    "\n",
    "# Resize descriptors to a consistent length\n",
    "desired_length = 1000\n",
    "# Initialize the label variable\n",
    "img_label = []\n",
    "feature_descriptors_fused = []\n",
    "\n",
    "\n",
    "def file_looper_transformer_extract_features_and_train():\n",
    "    source_data_label = \"\"\n",
    "    augmentation_seq = iaa.Sequential([\n",
    "        # iaa.Affine(rotate=(9, 10)),  # Rotate images by -10 to +10 degrees\n",
    "        iaa.Multiply((0.8, 1.0)),  # Multiply pixel values by a factor between 0.8 and 1.2\n",
    "        # iaa.GammaContrast(gamma=(2.0, 2.2)),  # Adjust gamma contrast between 0.8 and 1.2\n",
    "        # iaa.ElasticTransformation(alpha=50, sigma=5)  # Apply elastic transformations\n",
    "        # iaa.Fliplr(),  # Flip images horizontally with a 50% chance\n",
    "        # iaa.Multiply((0.8, 1.2)),  # Multiply pixel values by a factor between 0.8 and 1.2\n",
    "        # iaa.GammaContrast(),  # Adjust gamma contrast between 0.8 and 1.2\n",
    "        # iaa.ElasticTransformation(alpha=50, sigma=5)  # Apply elastic transformations\n",
    "        # iaa.Affine(rotate=(0, 10)),  # Rotate images by -10 to +10 degrees\n",
    "        # iaa.GaussianBlur(sigma=(0, 1.0)),  # Apply Gaussian blur with a sigma between 0 and 1.0\n",
    "        # iaa.AdditiveGaussianNoise(scale=(0, 0.05*255)),  # Add Gaussian noise with a scale of 0 to 0.05*255\n",
    "    ])\n",
    "    for dirname, _, filenames in os.walk('./jaffe'):\n",
    "        for filename in filenames:\n",
    "            # print(os.path.join(dirname, filename))\n",
    "            img_name, img_extention = os.path.splitext(filename)\n",
    "            expression_label = (os.path.join(dirname, filename)).split(os.sep)[2]\n",
    "            if source_data_label == '':\n",
    "                source_data_label = (os.path.join(dirname, filename)).split(os.sep)[1]\n",
    "\n",
    "            if(img_extention == \".jpg\" or img_extention == \".png\"):\n",
    "                image = cv2.imread(os.path.join(dirname, filename))\n",
    "                # Apply data augmentation\n",
    "                image = augmentation_seq(image=image)\n",
    "                \n",
    "                ext_feature, the_label = face_detection_extraction(image, expression_label)\n",
    "                feature_descriptors_fused.append(ext_feature)\n",
    "                img_label.append(expression_label)\n",
    "\n",
    "\n",
    "    # return feature_descriptors_fused, img_label\n",
    "    svmc(feature_descriptors_fused, img_label, source_data_label)\n",
    "\n",
    "\n",
    "def face_detection_extraction(image, image_label):\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = detector(gray, 1)\n",
    "    feature_list = []  # List to store the extracted features\n",
    "    label_list = []  # List to store the corresponding labels\n",
    "\n",
    "    for face in faces:\n",
    "        landmarks = predictor(gray, face)\n",
    "        x, y, w, h = face.left(), face.top(), face.width(), face.height()\n",
    "        extracted_face = image[y:y+h, x:x+w]\n",
    "        extracted_face = np.array(extracted_face)\n",
    "\n",
    "        shape = face_utils.shape_to_np(landmarks)\n",
    "        # Draw on our image, all the found 68 coordinate points (x,y)\n",
    "        for (x, y) in shape:\n",
    "            cv2.circle(image, (x, y), 2, (0, 255, 0), -1)\n",
    "        weight1 = 0.9  # Weight for descriptors lbp\n",
    "        weight2 = 0.9  # Weight for descriptors hog\n",
    "        weight3 = 0.2  # Weight for descriptors orb\n",
    "        weight4 = 0.2  # Weight for descriptors sift\n",
    "            \n",
    "        lbp_descriptors = lbp_extraction(extracted_face)\n",
    "        # Calculate the Z-scores for each descriptor\n",
    "        zscore_lbp_descriptors = (lbp_descriptors - np.mean(lbp_descriptors)) / np.std(lbp_descriptors)\n",
    "        # Fusion using weighted sum\n",
    "        lbp_descriptors = weight1 * zscore_lbp_descriptors \n",
    "        lbp_descriptors = np.resize(lbp_descriptors, (desired_length,))\n",
    "\n",
    "        orb_descriptors = orb_extraction(extracted_face)\n",
    "        # Calculate the Z-scores for each descriptor\n",
    "        # print(\" >>>\", np.std(orb_descriptors))\n",
    "        # print(\" <  > \", orb_descriptors - np.mean(orb_descriptors) )\n",
    "        try:\n",
    "            zscore_orb_descriptors = (orb_descriptors - np.mean(orb_descriptors)) / np.std(orb_descriptors)\n",
    "            # Fusion using weighted sum\n",
    "            orb_descriptors = weight3 * zscore_orb_descriptors \n",
    "            # print(\"orb_descriptors \", orb_descriptors)\n",
    "        except Exception as e:\n",
    "            # print(str(e))\n",
    "            pass\n",
    "        orb_descriptors = np.resize(orb_descriptors, (desired_length,))\n",
    "\n",
    "        # fused_features = lbp_descriptors + hog_descriptors + sift_descriptors\n",
    "        fused_features = lbp_descriptors\n",
    "        if orb_descriptors is not None:\n",
    "            fused_features += orb_descriptors.astype(np.float64)\n",
    "\n",
    "        # fused_features = np.concatenate((hog_descriptors, lbp_descriptors, sift_descriptors))\n",
    "\n",
    "        if len(fused_features) > 0:\n",
    "            feature_list.append(fused_features)\n",
    "            label_list.append(image_label)  # Add the label to the list\n",
    "\n",
    "    return feature_list, label_list\n",
    "\n",
    "        # print(fused_features)\n",
    "        \n",
    "        # Display the extracted faces\n",
    "        # cv2.imshow(\"Landmark localization\", extracted_face)\n",
    "        # plt.imshow(pixels)\n",
    "        # plt.axis('off')\n",
    "        # plt.show()\n",
    "\n",
    "def lbp_extraction(extracted_face):\n",
    "    # Compute LBP features\n",
    "\n",
    "    # Get the dimensions of the image\n",
    "    # height, width, channels = extracted_face.shape\n",
    "\n",
    "    # Compute LBP features\n",
    "    radius = 3\n",
    "    n_points = 8 * radius\n",
    "    # convert to 2 dimentional\n",
    "    extracted_face = cv2.cvtColor(extracted_face, cv2.COLOR_BGR2GRAY)\n",
    "    lbp_features = local_binary_pattern(extracted_face, n_points, radius, method='default')\n",
    "    # print(lbp_features)\n",
    "    disply_feature(\"LBP\", lbp_features)\n",
    "    return lbp_features\n",
    "\n",
    "def orb_extraction(extracted_face):\n",
    "    # Create an ORB object with custom parameters\n",
    "    orb = cv2.ORB_create(nfeatures=1000, scaleFactor=1.2, nlevels=8, edgeThreshold=15)\n",
    "    # Resize the extracted face to a larger size for better feature extraction\n",
    "    extracted_face = cv2.resize(extracted_face, (250, 250))\n",
    "    # Convert the face image to grayscale\n",
    "    extracted_face = cv2.cvtColor(extracted_face, cv2.COLOR_BGR2GRAY)\n",
    "    # Detect keypoints and compute descriptors\n",
    "    keypoints, descriptors = orb.detectAndCompute(extracted_face, None)\n",
    "    # Draw keypoints on the image\n",
    "    image_with_keypoints = cv2.drawKeypoints(extracted_face, keypoints, None, (0, 255, 0), cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "    # disply_feature(\"ORB\", image_with_keypoints)\n",
    "    return descriptors\n",
    "\n",
    "def disply_feature(features_type, features):\n",
    "    # cv2.imshow(features_type, features)\n",
    "    # # plt.imshow( features)\n",
    "    # plt.axis('off')\n",
    "    # plt.show()\n",
    "    pass\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "def svmc(fused_features, img_labels, source_data_label):\n",
    "    \n",
    "    # Create arrays to store the features and labels\n",
    "    fused_features = np.array(fused_features)\n",
    "    img_labels = np.array(img_labels)\n",
    "    \n",
    "    # Reshape the fused features to have two dimensions\n",
    "    # fused_features = fused_features.reshape(-1, fused_features.shape[2])\n",
    "    fused_features = fused_features.reshape(fused_features.shape[0], -1)\n",
    " \n",
    "    # Normalize the feature vectors\n",
    "    scaler = StandardScaler()\n",
    "    fused_features = scaler.fit_transform(fused_features)\n",
    "\n",
    "    # Handle missing values with an imputer transformer\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    fused_features = imputer.fit_transform(fused_features)\n",
    "\n",
    "    # Split the fused features data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(fused_features, img_labels, test_size=0.024, random_state=44)\n",
    "\n",
    "    # Create an SVM classifier\n",
    "    # instantiate classifier with linear kernel and C=100\n",
    "    svc = svm.SVC(kernel='linear', C=100)\n",
    "\n",
    "    # Train the classifier\n",
    "    svc.fit(X_train, y_train)\n",
    "\n",
    "    # Predict labels for the test set\n",
    "    y_pred = svc.predict(X_test)\n",
    "    # print(y_pred)\n",
    "    # print(\"< ---------------- >\")\n",
    "    # print(y_test)\n",
    "    # print(\"< ---------------- >\")\n",
    "    # print(X_train)\n",
    "    # print(\"< ---------------- >\")\n",
    "    # print(X_test)\n",
    "\n",
    "    # Evaluate the classifier's performance\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='macro', zero_division=1)\n",
    "    recall = recall_score(y_test, y_pred, average='macro', zero_division=1)\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    print(\" 2_without_hog_sift_algo algorithm \", source_data_label)\n",
    "    # Print the evaluation metrics\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F1 Score:\", f1)\n",
    "\n",
    "   \n",
    "    joblib.dump(svc, f\"2_without_hog_sift_algo_zscore_on_svm_classifier_{source_data_label}.joblib\")\n",
    "    # joblib.dump(svc, f\"lbp_zscore_on_svm_classifier_{source_data_label}.joblib\")\n",
    "    # joblib.dump(svc, f\"hog_on_svm_classifier_{source_data_label}.joblib\")\n",
    "    # joblib.dump(svc, f\"sift_on_svm_classifier_{source_data_label}.joblib\")\n",
    "\n",
    "file_looper_transformer_extract_features_and_train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "26b0ea46-2fa1-4eb0-a31d-e26402a07a59",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2_without_orb_sift_algo algorithm  jaffe\n",
      "Accuracy: 0.75\n",
      "Precision: 0.75\n",
      "Recall: 0.8611111111111112\n",
      "F1 Score: 0.6888888888888888\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from operator import le\n",
    "import cv2\n",
    "import dlib\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from imutils import face_utils\n",
    "from skimage.feature import hog, local_binary_pattern\n",
    "import mahotas as mh\n",
    "import joblib\n",
    "from sklearn import svm\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import imgaug.augmenters as iaa\n",
    "\n",
    "# Resize descriptors to a consistent length\n",
    "desired_length = 1000\n",
    "# Initialize the label variable\n",
    "img_label = []\n",
    "feature_descriptors_fused = []\n",
    "\n",
    "\n",
    "def file_looper_transformer_extract_features_and_train():\n",
    "    source_data_label = \"\"\n",
    "    augmentation_seq = iaa.Sequential([\n",
    "        # iaa.Affine(rotate=(9, 10)),  # Rotate images by -10 to +10 degrees\n",
    "        iaa.Multiply((0.8, 1.0)),  # Multiply pixel values by a factor between 0.8 and 1.2\n",
    "        # iaa.GammaContrast(gamma=(2.0, 2.2)),  # Adjust gamma contrast between 0.8 and 1.2\n",
    "        # iaa.ElasticTransformation(alpha=50, sigma=5)  # Apply elastic transformations\n",
    "        # iaa.Fliplr(),  # Flip images horizontally with a 50% chance\n",
    "        # iaa.Multiply((0.8, 1.2)),  # Multiply pixel values by a factor between 0.8 and 1.2\n",
    "        # iaa.GammaContrast(),  # Adjust gamma contrast between 0.8 and 1.2\n",
    "        # iaa.ElasticTransformation(alpha=50, sigma=5)  # Apply elastic transformations\n",
    "        # iaa.Affine(rotate=(0, 10)),  # Rotate images by -10 to +10 degrees\n",
    "        # iaa.GaussianBlur(sigma=(0, 1.0)),  # Apply Gaussian blur with a sigma between 0 and 1.0\n",
    "        # iaa.AdditiveGaussianNoise(scale=(0, 0.05*255)),  # Add Gaussian noise with a scale of 0 to 0.05*255\n",
    "    ])\n",
    "    for dirname, _, filenames in os.walk('./jaffe'):\n",
    "        for filename in filenames:\n",
    "            # print(os.path.join(dirname, filename))\n",
    "            img_name, img_extention = os.path.splitext(filename)\n",
    "            expression_label = (os.path.join(dirname, filename)).split(os.sep)[2]\n",
    "            if source_data_label == '':\n",
    "                source_data_label = (os.path.join(dirname, filename)).split(os.sep)[1]\n",
    "\n",
    "            if(img_extention == \".jpg\" or img_extention == \".png\"):\n",
    "                image = cv2.imread(os.path.join(dirname, filename))\n",
    "                # Apply data augmentation\n",
    "                image = augmentation_seq(image=image)\n",
    "                \n",
    "                ext_feature, the_label = face_detection_extraction(image, expression_label)\n",
    "                feature_descriptors_fused.append(ext_feature)\n",
    "                img_label.append(expression_label)\n",
    "\n",
    "\n",
    "    # return feature_descriptors_fused, img_label\n",
    "    svmc(feature_descriptors_fused, img_label, source_data_label)\n",
    "\n",
    "\n",
    "def face_detection_extraction(image, image_label):\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = detector(gray, 1)\n",
    "    feature_list = []  # List to store the extracted features\n",
    "    label_list = []  # List to store the corresponding labels\n",
    "\n",
    "    for face in faces:\n",
    "        landmarks = predictor(gray, face)\n",
    "        x, y, w, h = face.left(), face.top(), face.width(), face.height()\n",
    "        extracted_face = image[y:y+h, x:x+w]\n",
    "        extracted_face = np.array(extracted_face)\n",
    "\n",
    "        shape = face_utils.shape_to_np(landmarks)\n",
    "        # Draw on our image, all the found 68 coordinate points (x,y)\n",
    "        for (x, y) in shape:\n",
    "            cv2.circle(image, (x, y), 2, (0, 255, 0), -1)\n",
    "        weight1 = 0.9  # Weight for descriptors lbp\n",
    "        weight2 = 0.9  # Weight for descriptors hog\n",
    "        weight3 = 0.2  # Weight for descriptors orb\n",
    "        weight4 = 0.2  # Weight for descriptors sift\n",
    "            \n",
    "        hog_descriptors = hog_extraction(extracted_face)\n",
    "        try:  \n",
    "            # Calculate the Z-scores for each descriptor\n",
    "            zscore_hog_descriptors = (hog_descriptors - np.mean(hog_descriptors)) / np.std(hog_descriptors)\n",
    "            # Fusion using weighted sum\n",
    "            hog_descriptors = weight2 * zscore_hog_descriptors   \n",
    "        except Exception as e:\n",
    "            # print(str(e), np.std(hog_descriptors))\n",
    "            pass    \n",
    "        hog_descriptors = np.resize(hog_descriptors, (desired_length,))\n",
    "\n",
    "        lbp_descriptors = lbp_extraction(extracted_face)\n",
    "        # Calculate the Z-scores for each descriptor\n",
    "        zscore_lbp_descriptors = (lbp_descriptors - np.mean(lbp_descriptors)) / np.std(lbp_descriptors)\n",
    "        # Fusion using weighted sum\n",
    "        lbp_descriptors = weight1 * zscore_lbp_descriptors \n",
    "        lbp_descriptors = np.resize(lbp_descriptors, (desired_length,))\n",
    "\n",
    "        orb_descriptors = orb_extraction(extracted_face)\n",
    "        # Calculate the Z-scores for each descriptor\n",
    "        # print(\" >>>\", np.std(orb_descriptors))\n",
    "        # print(\" <  > \", orb_descriptors - np.mean(orb_descriptors) )\n",
    "        try:\n",
    "            zscore_orb_descriptors = (orb_descriptors - np.mean(orb_descriptors)) / np.std(orb_descriptors)\n",
    "            # Fusion using weighted sum\n",
    "            orb_descriptors = weight3 * zscore_orb_descriptors \n",
    "            # print(\"orb_descriptors \", orb_descriptors)\n",
    "        except Exception as e:\n",
    "            # print(str(e))\n",
    "            pass\n",
    "        orb_descriptors = np.resize(orb_descriptors, (desired_length,))\n",
    "\n",
    "        sift_descriptors = sift_extraction(extracted_face)\n",
    "        try:\n",
    "            # Calculate the Z-scores for each descriptor\n",
    "            zscore_sift_descriptors = (sift_descriptors - np.mean(sift_descriptors)) / np.std(sift_descriptors)\n",
    "            # Fusion using weighted sum\n",
    "            sift_descriptors = weight4 * zscore_sift_descriptors   \n",
    "        except Exception as e:\n",
    "            # print(str(e))\n",
    "            pass    \n",
    "        sift_descriptors = np.resize(sift_descriptors, (desired_length,))\n",
    "\n",
    "        # fused_features = lbp_descriptors + hog_descriptors + sift_descriptors\n",
    "        fused_features = hog_descriptors\n",
    "        if lbp_descriptors is not None:\n",
    "            fused_features += lbp_descriptors\n",
    "        # if sift_descriptors is not None:\n",
    "        #     fused_features += sift_descriptors.astype(np.float64)\n",
    "\n",
    "        # fused_features = np.concatenate((hog_descriptors, lbp_descriptors, sift_descriptors))\n",
    "\n",
    "        if len(fused_features) > 0:\n",
    "            feature_list.append(fused_features)\n",
    "            label_list.append(image_label)  # Add the label to the list\n",
    "\n",
    "    return feature_list, label_list\n",
    "\n",
    "        # print(fused_features)\n",
    "        \n",
    "        # Display the extracted faces\n",
    "        # cv2.imshow(\"Landmark localization\", extracted_face)\n",
    "        # plt.imshow(pixels)\n",
    "        # plt.axis('off')\n",
    "        # plt.show()\n",
    "\n",
    "def hog_extraction(extracted_face):\n",
    "    # Convert the image to grayscale\n",
    "    image_gray = cv2.cvtColor(extracted_face, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Define HOG parameters\n",
    "    orientations = 9  # Number of gradient orientations\n",
    "    pixels_per_cell = (8, 8)  # Cell size in pixels\n",
    "    cells_per_block = (2, 2)  # Number of cells in each block\n",
    "\n",
    "    # Compute HOG features\n",
    "    hog_image, hog_features = hog(image_gray, orientations=orientations, pixels_per_cell=pixels_per_cell, cells_per_block=cells_per_block, visualize=True)    \n",
    "    # print(hog_features)\n",
    "    disply_feature(\"HOG\", hog_features)\n",
    "    return hog_features\n",
    "\n",
    "def lbp_extraction(extracted_face):\n",
    "    # Compute LBP features\n",
    "\n",
    "    # Get the dimensions of the image\n",
    "    # height, width, channels = extracted_face.shape\n",
    "\n",
    "    # Compute LBP features\n",
    "    radius = 3\n",
    "    n_points = 8 * radius\n",
    "    # convert to 2 dimentional\n",
    "    extracted_face = cv2.cvtColor(extracted_face, cv2.COLOR_BGR2GRAY)\n",
    "    lbp_features = local_binary_pattern(extracted_face, n_points, radius, method='default')\n",
    "    # print(lbp_features)\n",
    "    disply_feature(\"LBP\", lbp_features)\n",
    "    return lbp_features\n",
    "\n",
    "# Scale-Invariant Feature Transform descriptor\n",
    "def sift_extraction(extracted_face):\n",
    "    # Create a SIFT object\n",
    "    sift = cv2.SIFT_create()\n",
    "    # Detect keypoints and compute descriptors\n",
    "    keypoints, descriptors = sift.detectAndCompute(extracted_face, None)\n",
    "    # Draw keypoints on the image\n",
    "    image_with_keypoints = cv2.drawKeypoints(extracted_face, keypoints, None)\n",
    "    # print(descriptors)\n",
    "    disply_feature(\"SIFT\", image_with_keypoints)\n",
    "    return descriptors\n",
    "\n",
    "def orb_extraction(extracted_face):\n",
    "    # Create an ORB object with custom parameters\n",
    "    orb = cv2.ORB_create(nfeatures=1000, scaleFactor=1.2, nlevels=8, edgeThreshold=15)\n",
    "    # Resize the extracted face to a larger size for better feature extraction\n",
    "    extracted_face = cv2.resize(extracted_face, (250, 250))\n",
    "    # Convert the face image to grayscale\n",
    "    extracted_face = cv2.cvtColor(extracted_face, cv2.COLOR_BGR2GRAY)\n",
    "    # Detect keypoints and compute descriptors\n",
    "    keypoints, descriptors = orb.detectAndCompute(extracted_face, None)\n",
    "    # Draw keypoints on the image\n",
    "    image_with_keypoints = cv2.drawKeypoints(extracted_face, keypoints, None, (0, 255, 0), cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "    # disply_feature(\"ORB\", image_with_keypoints)\n",
    "    return descriptors\n",
    "\n",
    "def disply_feature(features_type, features):\n",
    "    # cv2.imshow(features_type, features)\n",
    "    # # plt.imshow( features)\n",
    "    # plt.axis('off')\n",
    "    # plt.show()\n",
    "    pass\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "def svmc(fused_features, img_labels, source_data_label):\n",
    "    \n",
    "    # Create arrays to store the features and labels\n",
    "    fused_features = np.array(fused_features)\n",
    "    img_labels = np.array(img_labels)\n",
    "    \n",
    "    # Reshape the fused features to have two dimensions\n",
    "    # fused_features = fused_features.reshape(-1, fused_features.shape[2])\n",
    "    fused_features = fused_features.reshape(fused_features.shape[0], -1)\n",
    " \n",
    "    # Normalize the feature vectors\n",
    "    scaler = StandardScaler()\n",
    "    fused_features = scaler.fit_transform(fused_features)\n",
    "\n",
    "    # Handle missing values with an imputer transformer\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    fused_features = imputer.fit_transform(fused_features)\n",
    "\n",
    "    # Split the fused features data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(fused_features, img_labels, test_size=0.034, random_state=44)\n",
    "\n",
    "    # Create an SVM classifier\n",
    "    # instantiate classifier with linear kernel and C=100\n",
    "    svc = svm.SVC(kernel='linear', C=100)\n",
    "\n",
    "    # Train the classifier\n",
    "    svc.fit(X_train, y_train)\n",
    "\n",
    "    # Predict labels for the test set\n",
    "    y_pred = svc.predict(X_test)\n",
    "    # print(y_pred)\n",
    "    # print(\"< ---------------- >\")\n",
    "    # print(y_test)\n",
    "    # print(\"< ---------------- >\")\n",
    "    # print(X_train)\n",
    "    # print(\"< ---------------- >\")\n",
    "    # print(X_test)\n",
    "\n",
    "    # Evaluate the classifier's performance\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='macro', zero_division=1)\n",
    "    recall = recall_score(y_test, y_pred, average='macro', zero_division=1)\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    print(\" 2_without_orb_sift_algo algorithm \", source_data_label)\n",
    "    # Print the evaluation metrics\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F1 Score:\", f1)\n",
    "\n",
    "   \n",
    "    joblib.dump(svc, f\"2_without_orb_sift_algo_zscore_on_svm_classifier_{source_data_label}.joblib\")\n",
    "    # joblib.dump(svc, f\"lbp_zscore_on_svm_classifier_{source_data_label}.joblib\")\n",
    "    # joblib.dump(svc, f\"hog_on_svm_classifier_{source_data_label}.joblib\")\n",
    "    # joblib.dump(svc, f\"sift_on_svm_classifier_{source_data_label}.joblib\")\n",
    "\n",
    "file_looper_transformer_extract_features_and_train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c8a1be-9ad4-4254-b7a9-9c98689e6610",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b7917c4c-963f-4003-8728-90647f571d78",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 3_without_orb_algo algorithm  jaffe\n",
      "Accuracy: 0.75\n",
      "Precision: 0.75\n",
      "Recall: 0.861111111111111\n",
      "F1 Score: 0.6888888888888888\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from operator import le\n",
    "import cv2\n",
    "import dlib\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from imutils import face_utils\n",
    "from skimage.feature import hog, local_binary_pattern\n",
    "import mahotas as mh\n",
    "import joblib\n",
    "from sklearn import svm\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import imgaug.augmenters as iaa\n",
    "\n",
    "# Resize descriptors to a consistent length\n",
    "desired_length = 1000\n",
    "# Initialize the label variable\n",
    "img_label = []\n",
    "feature_descriptors_fused = []\n",
    "\n",
    "\n",
    "def file_looper_transformer_extract_features_and_train():\n",
    "    source_data_label = \"\"\n",
    "    augmentation_seq = iaa.Sequential([\n",
    "        # iaa.Affine(rotate=(9, 10)),  # Rotate images by -10 to +10 degrees\n",
    "        iaa.Multiply((0.8, 1.0)),  # Multiply pixel values by a factor between 0.8 and 1.2\n",
    "        # iaa.GammaContrast(gamma=(2.0, 2.2)),  # Adjust gamma contrast between 0.8 and 1.2\n",
    "        # iaa.ElasticTransformation(alpha=50, sigma=5)  # Apply elastic transformations\n",
    "        # iaa.Fliplr(),  # Flip images horizontally with a 50% chance\n",
    "        # iaa.Multiply((0.8, 1.2)),  # Multiply pixel values by a factor between 0.8 and 1.2\n",
    "        # iaa.GammaContrast(),  # Adjust gamma contrast between 0.8 and 1.2\n",
    "        # iaa.ElasticTransformation(alpha=50, sigma=5)  # Apply elastic transformations\n",
    "        # iaa.Affine(rotate=(0, 10)),  # Rotate images by -10 to +10 degrees\n",
    "        # iaa.GaussianBlur(sigma=(0, 1.0)),  # Apply Gaussian blur with a sigma between 0 and 1.0\n",
    "        # iaa.AdditiveGaussianNoise(scale=(0, 0.05*255)),  # Add Gaussian noise with a scale of 0 to 0.05*255\n",
    "    ])\n",
    "    for dirname, _, filenames in os.walk('./jaffe'):\n",
    "        for filename in filenames:\n",
    "            # print(os.path.join(dirname, filename))\n",
    "            img_name, img_extention = os.path.splitext(filename)\n",
    "            expression_label = (os.path.join(dirname, filename)).split(os.sep)[2]\n",
    "            if source_data_label == '':\n",
    "                source_data_label = (os.path.join(dirname, filename)).split(os.sep)[1]\n",
    "\n",
    "            if(img_extention == \".jpg\" or img_extention == \".png\"):\n",
    "                image = cv2.imread(os.path.join(dirname, filename))\n",
    "                # Apply data augmentation\n",
    "                image = augmentation_seq(image=image)\n",
    "                \n",
    "                ext_feature, the_label = face_detection_extraction(image, expression_label)\n",
    "                feature_descriptors_fused.append(ext_feature)\n",
    "                img_label.append(expression_label)\n",
    "\n",
    "\n",
    "    # return feature_descriptors_fused, img_label\n",
    "    svmc(feature_descriptors_fused, img_label, source_data_label)\n",
    "\n",
    "\n",
    "def face_detection_extraction(image, image_label):\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = detector(gray, 1)\n",
    "    feature_list = []  # List to store the extracted features\n",
    "    label_list = []  # List to store the corresponding labels\n",
    "\n",
    "    for face in faces:\n",
    "        landmarks = predictor(gray, face)\n",
    "        x, y, w, h = face.left(), face.top(), face.width(), face.height()\n",
    "        extracted_face = image[y:y+h, x:x+w]\n",
    "        extracted_face = np.array(extracted_face)\n",
    "\n",
    "        shape = face_utils.shape_to_np(landmarks)\n",
    "        # Draw on our image, all the found 68 coordinate points (x,y)\n",
    "        for (x, y) in shape:\n",
    "            cv2.circle(image, (x, y), 2, (0, 255, 0), -1)\n",
    "        weight1 = 0.9  # Weight for descriptors lbp\n",
    "        weight2 = 0.9  # Weight for descriptors hog\n",
    "        weight3 = 0.2  # Weight for descriptors orb\n",
    "        weight4 = 0.2  # Weight for descriptors sift\n",
    "            \n",
    "        hog_descriptors = hog_extraction(extracted_face)\n",
    "        try:  \n",
    "            # Calculate the Z-scores for each descriptor\n",
    "            zscore_hog_descriptors = (hog_descriptors - np.mean(hog_descriptors)) / np.std(hog_descriptors)\n",
    "            # Fusion using weighted sum\n",
    "            hog_descriptors = weight2 * zscore_hog_descriptors   \n",
    "        except Exception as e:\n",
    "            # print(str(e), np.std(hog_descriptors))\n",
    "            pass    \n",
    "        hog_descriptors = np.resize(hog_descriptors, (desired_length,))\n",
    "\n",
    "        lbp_descriptors = lbp_extraction(extracted_face)\n",
    "        # Calculate the Z-scores for each descriptor\n",
    "        zscore_lbp_descriptors = (lbp_descriptors - np.mean(lbp_descriptors)) / np.std(lbp_descriptors)\n",
    "        # Fusion using weighted sum\n",
    "        lbp_descriptors = weight1 * zscore_lbp_descriptors \n",
    "        lbp_descriptors = np.resize(lbp_descriptors, (desired_length,))\n",
    "\n",
    "        orb_descriptors = orb_extraction(extracted_face)\n",
    "        # Calculate the Z-scores for each descriptor\n",
    "        # print(\" >>>\", np.std(orb_descriptors))\n",
    "        # print(\" <  > \", orb_descriptors - np.mean(orb_descriptors) )\n",
    "        try:\n",
    "            zscore_orb_descriptors = (orb_descriptors - np.mean(orb_descriptors)) / np.std(orb_descriptors)\n",
    "            # Fusion using weighted sum\n",
    "            orb_descriptors = weight3 * zscore_orb_descriptors \n",
    "            # print(\"orb_descriptors \", orb_descriptors)\n",
    "        except Exception as e:\n",
    "            # print(str(e))\n",
    "            pass\n",
    "        orb_descriptors = np.resize(orb_descriptors, (desired_length,))\n",
    "\n",
    "        sift_descriptors = sift_extraction(extracted_face)\n",
    "        try:\n",
    "            # Calculate the Z-scores for each descriptor\n",
    "            zscore_sift_descriptors = (sift_descriptors - np.mean(sift_descriptors)) / np.std(sift_descriptors)\n",
    "            # Fusion using weighted sum\n",
    "            sift_descriptors = weight4 * zscore_sift_descriptors   \n",
    "        except Exception as e:\n",
    "            # print(str(e))\n",
    "            pass    \n",
    "        sift_descriptors = np.resize(sift_descriptors, (desired_length,))\n",
    "\n",
    "        # fused_features = lbp_descriptors + hog_descriptors + sift_descriptors\n",
    "        fused_features = hog_descriptors\n",
    "        if lbp_descriptors is not None:\n",
    "            fused_features += lbp_descriptors\n",
    "        if sift_descriptors is not None:\n",
    "            fused_features += sift_descriptors.astype(np.float64)\n",
    "\n",
    "        # fused_features = np.concatenate((hog_descriptors, lbp_descriptors, sift_descriptors))\n",
    "\n",
    "        if len(fused_features) > 0:\n",
    "            feature_list.append(fused_features)\n",
    "            label_list.append(image_label)  # Add the label to the list\n",
    "\n",
    "    return feature_list, label_list\n",
    "\n",
    "        # print(fused_features)\n",
    "        \n",
    "        # Display the extracted faces\n",
    "        # cv2.imshow(\"Landmark localization\", extracted_face)\n",
    "        # plt.imshow(pixels)\n",
    "        # plt.axis('off')\n",
    "        # plt.show()\n",
    "\n",
    "def hog_extraction(extracted_face):\n",
    "    # Convert the image to grayscale\n",
    "    image_gray = cv2.cvtColor(extracted_face, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Define HOG parameters\n",
    "    orientations = 9  # Number of gradient orientations\n",
    "    pixels_per_cell = (8, 8)  # Cell size in pixels\n",
    "    cells_per_block = (2, 2)  # Number of cells in each block\n",
    "\n",
    "    # Compute HOG features\n",
    "    hog_image, hog_features = hog(image_gray, orientations=orientations, pixels_per_cell=pixels_per_cell, cells_per_block=cells_per_block, visualize=True)    \n",
    "    # print(hog_features)\n",
    "    disply_feature(\"HOG\", hog_features)\n",
    "    return hog_features\n",
    "\n",
    "def lbp_extraction(extracted_face):\n",
    "    # Compute LBP features\n",
    "\n",
    "    # Get the dimensions of the image\n",
    "    # height, width, channels = extracted_face.shape\n",
    "\n",
    "    # Compute LBP features\n",
    "    radius = 3\n",
    "    n_points = 8 * radius\n",
    "    # convert to 2 dimentional\n",
    "    extracted_face = cv2.cvtColor(extracted_face, cv2.COLOR_BGR2GRAY)\n",
    "    lbp_features = local_binary_pattern(extracted_face, n_points, radius, method='default')\n",
    "    # print(lbp_features)\n",
    "    disply_feature(\"LBP\", lbp_features)\n",
    "    return lbp_features\n",
    "\n",
    "# Scale-Invariant Feature Transform descriptor\n",
    "def sift_extraction(extracted_face):\n",
    "    # Create a SIFT object\n",
    "    sift = cv2.SIFT_create()\n",
    "    # Detect keypoints and compute descriptors\n",
    "    keypoints, descriptors = sift.detectAndCompute(extracted_face, None)\n",
    "    # Draw keypoints on the image\n",
    "    image_with_keypoints = cv2.drawKeypoints(extracted_face, keypoints, None)\n",
    "    # print(descriptors)\n",
    "    disply_feature(\"SIFT\", image_with_keypoints)\n",
    "    return descriptors\n",
    "\n",
    "def orb_extraction(extracted_face):\n",
    "    # Create an ORB object with custom parameters\n",
    "    orb = cv2.ORB_create(nfeatures=1000, scaleFactor=1.2, nlevels=8, edgeThreshold=15)\n",
    "    # Resize the extracted face to a larger size for better feature extraction\n",
    "    extracted_face = cv2.resize(extracted_face, (250, 250))\n",
    "    # Convert the face image to grayscale\n",
    "    extracted_face = cv2.cvtColor(extracted_face, cv2.COLOR_BGR2GRAY)\n",
    "    # Detect keypoints and compute descriptors\n",
    "    keypoints, descriptors = orb.detectAndCompute(extracted_face, None)\n",
    "    # Draw keypoints on the image\n",
    "    image_with_keypoints = cv2.drawKeypoints(extracted_face, keypoints, None, (0, 255, 0), cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "    # disply_feature(\"ORB\", image_with_keypoints)\n",
    "    return descriptors\n",
    "\n",
    "def disply_feature(features_type, features):\n",
    "    # cv2.imshow(features_type, features)\n",
    "    # # plt.imshow( features)\n",
    "    # plt.axis('off')\n",
    "    # plt.show()\n",
    "    pass\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "def svmc(fused_features, img_labels, source_data_label):\n",
    "    \n",
    "    # Create arrays to store the features and labels\n",
    "    fused_features = np.array(fused_features)\n",
    "    img_labels = np.array(img_labels)\n",
    "    \n",
    "    # Reshape the fused features to have two dimensions\n",
    "    # fused_features = fused_features.reshape(-1, fused_features.shape[2])\n",
    "    fused_features = fused_features.reshape(fused_features.shape[0], -1)\n",
    " \n",
    "    # Normalize the feature vectors\n",
    "    scaler = StandardScaler()\n",
    "    fused_features = scaler.fit_transform(fused_features)\n",
    "\n",
    "    # Handle missing values with an imputer transformer\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    fused_features = imputer.fit_transform(fused_features)\n",
    "\n",
    "    # Split the fused features data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(fused_features, img_labels, test_size=0.034, random_state=44)\n",
    "\n",
    "    # Create an SVM classifier\n",
    "    # instantiate classifier with linear kernel and C=100\n",
    "    svc = svm.SVC(kernel='linear', C=100)\n",
    "\n",
    "    # Train the classifier\n",
    "    svc.fit(X_train, y_train)\n",
    "\n",
    "    # Predict labels for the test set\n",
    "    y_pred = svc.predict(X_test)\n",
    "    # print(y_pred)\n",
    "    # print(\"< ---------------- >\")\n",
    "    # print(y_test)\n",
    "    # print(\"< ---------------- >\")\n",
    "    # print(X_train)\n",
    "    # print(\"< ---------------- >\")\n",
    "    # print(X_test)\n",
    "\n",
    "    # Evaluate the classifier's performance\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='macro', zero_division=1)\n",
    "    recall = recall_score(y_test, y_pred, average='macro', zero_division=1)\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    print(\" 3_without_orb_algo algorithm \", source_data_label)\n",
    "    # Print the evaluation metrics\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F1 Score:\", f1)\n",
    "\n",
    "   \n",
    "    joblib.dump(svc, f\"3_without_orb_algo_zscore_on_svm_classifier_{source_data_label}.joblib\")\n",
    "    # joblib.dump(svc, f\"lbp_zscore_on_svm_classifier_{source_data_label}.joblib\")\n",
    "    # joblib.dump(svc, f\"hog_on_svm_classifier_{source_data_label}.joblib\")\n",
    "    # joblib.dump(svc, f\"sift_on_svm_classifier_{source_data_label}.joblib\")\n",
    "\n",
    "file_looper_transformer_extract_features_and_train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1fde36ad-6145-454d-bb78-39ff3981c0db",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 3_without_sift_algo algorithm  jaffe\n",
      "Accuracy: 0.5\n",
      "Precision: 0.7142857142857143\n",
      "Recall: 0.6428571428571429\n",
      "F1 Score: 0.38095238095238093\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from operator import le\n",
    "import cv2\n",
    "import dlib\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from imutils import face_utils\n",
    "from skimage.feature import hog, local_binary_pattern\n",
    "import mahotas as mh\n",
    "import joblib\n",
    "from sklearn import svm\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import imgaug.augmenters as iaa\n",
    "\n",
    "# Resize descriptors to a consistent length\n",
    "desired_length = 1000\n",
    "# Initialize the label variable\n",
    "img_label = []\n",
    "feature_descriptors_fused = []\n",
    "\n",
    "\n",
    "def file_looper_transformer_extract_features_and_train():\n",
    "    source_data_label = \"\"\n",
    "    augmentation_seq = iaa.Sequential([\n",
    "        # iaa.Affine(rotate=(9, 10)),  # Rotate images by -10 to +10 degrees\n",
    "        iaa.Multiply((0.8, 1.0)),  # Multiply pixel values by a factor between 0.8 and 1.2\n",
    "        # iaa.GammaContrast(gamma=(2.0, 2.2)),  # Adjust gamma contrast between 0.8 and 1.2\n",
    "        # iaa.ElasticTransformation(alpha=50, sigma=5)  # Apply elastic transformations\n",
    "        # iaa.Fliplr(),  # Flip images horizontally with a 50% chance\n",
    "        # iaa.Multiply((0.8, 1.2)),  # Multiply pixel values by a factor between 0.8 and 1.2\n",
    "        # iaa.GammaContrast(),  # Adjust gamma contrast between 0.8 and 1.2\n",
    "        # iaa.ElasticTransformation(alpha=50, sigma=5)  # Apply elastic transformations\n",
    "        # iaa.Affine(rotate=(0, 10)),  # Rotate images by -10 to +10 degrees\n",
    "        # iaa.GaussianBlur(sigma=(0, 1.0)),  # Apply Gaussian blur with a sigma between 0 and 1.0\n",
    "        # iaa.AdditiveGaussianNoise(scale=(0, 0.05*255)),  # Add Gaussian noise with a scale of 0 to 0.05*255\n",
    "    ])\n",
    "    for dirname, _, filenames in os.walk('./jaffe'):\n",
    "        for filename in filenames:\n",
    "            # print(os.path.join(dirname, filename))\n",
    "            img_name, img_extention = os.path.splitext(filename)\n",
    "            expression_label = (os.path.join(dirname, filename)).split(os.sep)[2]\n",
    "            if source_data_label == '':\n",
    "                source_data_label = (os.path.join(dirname, filename)).split(os.sep)[1]\n",
    "\n",
    "            if(img_extention == \".jpg\" or img_extention == \".png\"):\n",
    "                image = cv2.imread(os.path.join(dirname, filename))\n",
    "                # Apply data augmentation\n",
    "                image = augmentation_seq(image=image)\n",
    "                \n",
    "                ext_feature, the_label = face_detection_extraction(image, expression_label)\n",
    "                feature_descriptors_fused.append(ext_feature)\n",
    "                img_label.append(expression_label)\n",
    "\n",
    "\n",
    "    # return feature_descriptors_fused, img_label\n",
    "    svmc(feature_descriptors_fused, img_label, source_data_label)\n",
    "\n",
    "\n",
    "def face_detection_extraction(image, image_label):\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = detector(gray, 1)\n",
    "    feature_list = []  # List to store the extracted features\n",
    "    label_list = []  # List to store the corresponding labels\n",
    "\n",
    "    for face in faces:\n",
    "        landmarks = predictor(gray, face)\n",
    "        x, y, w, h = face.left(), face.top(), face.width(), face.height()\n",
    "        extracted_face = image[y:y+h, x:x+w]\n",
    "        extracted_face = np.array(extracted_face)\n",
    "\n",
    "        shape = face_utils.shape_to_np(landmarks)\n",
    "        # Draw on our image, all the found 68 coordinate points (x,y)\n",
    "        for (x, y) in shape:\n",
    "            cv2.circle(image, (x, y), 2, (0, 255, 0), -1)\n",
    "        weight1 = 0.9  # Weight for descriptors lbp\n",
    "        weight2 = 0.9  # Weight for descriptors hog\n",
    "        weight3 = 0.2  # Weight for descriptors orb\n",
    "        weight4 = 0.2  # Weight for descriptors sift\n",
    "            \n",
    "        hog_descriptors = hog_extraction(extracted_face)\n",
    "        try:  \n",
    "            # Calculate the Z-scores for each descriptor\n",
    "            zscore_hog_descriptors = (hog_descriptors - np.mean(hog_descriptors)) / np.std(hog_descriptors)\n",
    "            # Fusion using weighted sum\n",
    "            hog_descriptors = weight2 * zscore_hog_descriptors   \n",
    "        except Exception as e:\n",
    "            # print(str(e), np.std(hog_descriptors))\n",
    "            pass    \n",
    "        hog_descriptors = np.resize(hog_descriptors, (desired_length,))\n",
    "\n",
    "        lbp_descriptors = lbp_extraction(extracted_face)\n",
    "        # Calculate the Z-scores for each descriptor\n",
    "        zscore_lbp_descriptors = (lbp_descriptors - np.mean(lbp_descriptors)) / np.std(lbp_descriptors)\n",
    "        # Fusion using weighted sum\n",
    "        lbp_descriptors = weight1 * zscore_lbp_descriptors \n",
    "        lbp_descriptors = np.resize(lbp_descriptors, (desired_length,))\n",
    "\n",
    "        orb_descriptors = orb_extraction(extracted_face)\n",
    "        # Calculate the Z-scores for each descriptor\n",
    "        # print(\" >>>\", np.std(orb_descriptors))\n",
    "        # print(\" <  > \", orb_descriptors - np.mean(orb_descriptors) )\n",
    "        try:\n",
    "            zscore_orb_descriptors = (orb_descriptors - np.mean(orb_descriptors)) / np.std(orb_descriptors)\n",
    "            # Fusion using weighted sum\n",
    "            orb_descriptors = weight3 * zscore_orb_descriptors \n",
    "            # print(\"orb_descriptors \", orb_descriptors)\n",
    "        except Exception as e:\n",
    "            # print(str(e))\n",
    "            pass\n",
    "        orb_descriptors = np.resize(orb_descriptors, (desired_length,))\n",
    "\n",
    "        sift_descriptors = sift_extraction(extracted_face)\n",
    "        try:\n",
    "            # Calculate the Z-scores for each descriptor\n",
    "            zscore_sift_descriptors = (sift_descriptors - np.mean(sift_descriptors)) / np.std(sift_descriptors)\n",
    "            # Fusion using weighted sum\n",
    "            sift_descriptors = weight4 * zscore_sift_descriptors   \n",
    "        except Exception as e:\n",
    "            # print(str(e))\n",
    "            pass    \n",
    "        sift_descriptors = np.resize(sift_descriptors, (desired_length,))\n",
    "\n",
    "        # fused_features = lbp_descriptors + hog_descriptors + sift_descriptors\n",
    "        fused_features = hog_descriptors\n",
    "        if lbp_descriptors is not None:\n",
    "            fused_features += lbp_descriptors\n",
    "        # if sift_descriptors is not None:\n",
    "        #     fused_features += sift_descriptors.astype(np.float64)\n",
    "        if orb_descriptors is not None:\n",
    "            fused_features += orb_descriptors.astype(np.float64)\n",
    "\n",
    "        # fused_features = np.concatenate((hog_descriptors, lbp_descriptors, sift_descriptors))\n",
    "\n",
    "        if len(fused_features) > 0:\n",
    "            feature_list.append(fused_features)\n",
    "            label_list.append(image_label)  # Add the label to the list\n",
    "\n",
    "    return feature_list, label_list\n",
    "\n",
    "        # print(fused_features)\n",
    "        \n",
    "        # Display the extracted faces\n",
    "        # cv2.imshow(\"Landmark localization\", extracted_face)\n",
    "        # plt.imshow(pixels)\n",
    "        # plt.axis('off')\n",
    "        # plt.show()\n",
    "\n",
    "def hog_extraction(extracted_face):\n",
    "    # Convert the image to grayscale\n",
    "    image_gray = cv2.cvtColor(extracted_face, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Define HOG parameters\n",
    "    orientations = 9  # Number of gradient orientations\n",
    "    pixels_per_cell = (8, 8)  # Cell size in pixels\n",
    "    cells_per_block = (2, 2)  # Number of cells in each block\n",
    "\n",
    "    # Compute HOG features\n",
    "    hog_image, hog_features = hog(image_gray, orientations=orientations, pixels_per_cell=pixels_per_cell, cells_per_block=cells_per_block, visualize=True)    \n",
    "    # print(hog_features)\n",
    "    disply_feature(\"HOG\", hog_features)\n",
    "    return hog_features\n",
    "\n",
    "def lbp_extraction(extracted_face):\n",
    "    # Compute LBP features\n",
    "\n",
    "    # Get the dimensions of the image\n",
    "    # height, width, channels = extracted_face.shape\n",
    "\n",
    "    # Compute LBP features\n",
    "    radius = 3\n",
    "    n_points = 8 * radius\n",
    "    # convert to 2 dimentional\n",
    "    extracted_face = cv2.cvtColor(extracted_face, cv2.COLOR_BGR2GRAY)\n",
    "    lbp_features = local_binary_pattern(extracted_face, n_points, radius, method='default')\n",
    "    # print(lbp_features)\n",
    "    disply_feature(\"LBP\", lbp_features)\n",
    "    return lbp_features\n",
    "\n",
    "# Scale-Invariant Feature Transform descriptor\n",
    "def sift_extraction(extracted_face):\n",
    "    # Create a SIFT object\n",
    "    sift = cv2.SIFT_create()\n",
    "    # Detect keypoints and compute descriptors\n",
    "    keypoints, descriptors = sift.detectAndCompute(extracted_face, None)\n",
    "    # Draw keypoints on the image\n",
    "    image_with_keypoints = cv2.drawKeypoints(extracted_face, keypoints, None)\n",
    "    # print(descriptors)\n",
    "    disply_feature(\"SIFT\", image_with_keypoints)\n",
    "    return descriptors\n",
    "\n",
    "def orb_extraction(extracted_face):\n",
    "    # Create an ORB object with custom parameters\n",
    "    orb = cv2.ORB_create(nfeatures=1000, scaleFactor=1.2, nlevels=8, edgeThreshold=15)\n",
    "    # Resize the extracted face to a larger size for better feature extraction\n",
    "    extracted_face = cv2.resize(extracted_face, (250, 250))\n",
    "    # Convert the face image to grayscale\n",
    "    extracted_face = cv2.cvtColor(extracted_face, cv2.COLOR_BGR2GRAY)\n",
    "    # Detect keypoints and compute descriptors\n",
    "    keypoints, descriptors = orb.detectAndCompute(extracted_face, None)\n",
    "    # Draw keypoints on the image\n",
    "    image_with_keypoints = cv2.drawKeypoints(extracted_face, keypoints, None, (0, 255, 0), cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "    # disply_feature(\"ORB\", image_with_keypoints)\n",
    "    return descriptors\n",
    "\n",
    "def disply_feature(features_type, features):\n",
    "    # cv2.imshow(features_type, features)\n",
    "    # # plt.imshow( features)\n",
    "    # plt.axis('off')\n",
    "    # plt.show()\n",
    "    pass\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "def svmc(fused_features, img_labels, source_data_label):\n",
    "    \n",
    "    # Create arrays to store the features and labels\n",
    "    fused_features = np.array(fused_features)\n",
    "    img_labels = np.array(img_labels)\n",
    "    \n",
    "    # Reshape the fused features to have two dimensions\n",
    "    # fused_features = fused_features.reshape(-1, fused_features.shape[2])\n",
    "    fused_features = fused_features.reshape(fused_features.shape[0], -1)\n",
    " \n",
    "    # Normalize the feature vectors\n",
    "    scaler = StandardScaler()\n",
    "    fused_features = scaler.fit_transform(fused_features)\n",
    "\n",
    "    # Handle missing values with an imputer transformer\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    fused_features = imputer.fit_transform(fused_features)\n",
    "\n",
    "    # Split the fused features data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(fused_features, img_labels, test_size=0.024, random_state=41)\n",
    "\n",
    "    # Create an SVM classifier\n",
    "    # instantiate classifier with linear kernel and C=100\n",
    "    svc = svm.SVC(kernel='linear', C=100)\n",
    "\n",
    "    # Train the classifier\n",
    "    svc.fit(X_train, y_train)\n",
    "\n",
    "    # Predict labels for the test set\n",
    "    y_pred = svc.predict(X_test)\n",
    "    # print(y_pred)\n",
    "    # print(\"< ---------------- >\")\n",
    "    # print(y_test)\n",
    "    # print(\"< ---------------- >\")\n",
    "    # print(X_train)\n",
    "    # print(\"< ---------------- >\")\n",
    "    # print(X_test)\n",
    "\n",
    "    # Evaluate the classifier's performance\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='macro', zero_division=1)\n",
    "    recall = recall_score(y_test, y_pred, average='macro', zero_division=1)\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    print(\" 3_without_sift_algo algorithm \", source_data_label)\n",
    "    # Print the evaluation metrics\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F1 Score:\", f1)\n",
    "\n",
    "   \n",
    "    joblib.dump(svc, f\"3_without_sift_algo_zscore_on_svm_classifier_{source_data_label}.joblib\")\n",
    "    # joblib.dump(svc, f\"lbp_zscore_on_svm_classifier_{source_data_label}.joblib\")\n",
    "    # joblib.dump(svc, f\"hog_on_svm_classifier_{source_data_label}.joblib\")\n",
    "    # joblib.dump(svc, f\"sift_on_svm_classifier_{source_data_label}.joblib\")\n",
    "\n",
    "file_looper_transformer_extract_features_and_train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5145a6a4-a2b3-4d32-9f3f-b3bd4c6d9677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kkkkkkkkkkkkkkkkk\n"
     ]
    }
   ],
   "source": [
    "print(\"kkkkkkkkkkkkkkkkk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ead28672-e541-48ec-8df0-f45d2d94e95f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 3_without_orb_algo algorithm  jaffe\n",
      "Accuracy: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1 Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from operator import le\n",
    "import cv2\n",
    "import dlib\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from imutils import face_utils\n",
    "from skimage.feature import hog, local_binary_pattern\n",
    "import mahotas as mh\n",
    "import joblib\n",
    "from sklearn import svm\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import imgaug.augmenters as iaa\n",
    "\n",
    "# Resize descriptors to a consistent length\n",
    "desired_length = 1000\n",
    "# Initialize the label variable\n",
    "img_label = []\n",
    "feature_descriptors_fused = []\n",
    "\n",
    "\n",
    "def file_looper_transformer_extract_features_and_train():\n",
    "    source_data_label = \"\"\n",
    "    augmentation_seq = iaa.Sequential([\n",
    "        # iaa.Affine(rotate=(9, 10)),  # Rotate images by -10 to +10 degrees\n",
    "        iaa.Multiply((0.8, 1.0)),  # Multiply pixel values by a factor between 0.8 and 1.2\n",
    "        # iaa.GammaContrast(gamma=(2.0, 2.2)),  # Adjust gamma contrast between 0.8 and 1.2\n",
    "        # iaa.ElasticTransformation(alpha=50, sigma=5)  # Apply elastic transformations\n",
    "        # iaa.Fliplr(),  # Flip images horizontally with a 50% chance\n",
    "        # iaa.Multiply((0.8, 1.2)),  # Multiply pixel values by a factor between 0.8 and 1.2\n",
    "        # iaa.GammaContrast(),  # Adjust gamma contrast between 0.8 and 1.2\n",
    "        # iaa.ElasticTransformation(alpha=50, sigma=5)  # Apply elastic transformations\n",
    "        # iaa.Affine(rotate=(0, 10)),  # Rotate images by -10 to +10 degrees\n",
    "        # iaa.GaussianBlur(sigma=(0, 1.0)),  # Apply Gaussian blur with a sigma between 0 and 1.0\n",
    "        # iaa.AdditiveGaussianNoise(scale=(0, 0.05*255)),  # Add Gaussian noise with a scale of 0 to 0.05*255\n",
    "    ])\n",
    "    for dirname, _, filenames in os.walk('./jaffe'):\n",
    "        for filename in filenames:\n",
    "            # print(os.path.join(dirname, filename))\n",
    "            img_name, img_extention = os.path.splitext(filename)\n",
    "            expression_label = (os.path.join(dirname, filename)).split(os.sep)[2]\n",
    "            if source_data_label == '':\n",
    "                source_data_label = (os.path.join(dirname, filename)).split(os.sep)[1]\n",
    "\n",
    "            if(img_extention == \".jpg\" or img_extention == \".png\"):\n",
    "                image = cv2.imread(os.path.join(dirname, filename))\n",
    "                # Apply data augmentation\n",
    "                image = augmentation_seq(image=image)\n",
    "                \n",
    "                ext_feature, the_label = face_detection_extraction(image, expression_label)\n",
    "                feature_descriptors_fused.append(ext_feature)\n",
    "                img_label.append(expression_label)\n",
    "\n",
    "\n",
    "    # return feature_descriptors_fused, img_label\n",
    "    svmc(feature_descriptors_fused, img_label, source_data_label)\n",
    "\n",
    "\n",
    "def face_detection_extraction(image, image_label):\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = detector(gray, 1)\n",
    "    feature_list = []  # List to store the extracted features\n",
    "    label_list = []  # List to store the corresponding labels\n",
    "\n",
    "    for face in faces:\n",
    "        landmarks = predictor(gray, face)\n",
    "        x, y, w, h = face.left(), face.top(), face.width(), face.height()\n",
    "        extracted_face = image[y:y+h, x:x+w]\n",
    "        extracted_face = np.array(extracted_face)\n",
    "\n",
    "        shape = face_utils.shape_to_np(landmarks)\n",
    "        # Draw on our image, all the found 68 coordinate points (x,y)\n",
    "        for (x, y) in shape:\n",
    "            cv2.circle(image, (x, y), 2, (0, 255, 0), -1)\n",
    "        weight1 = 0.9  # Weight for descriptors lbp\n",
    "        weight2 = 0.9  # Weight for descriptors hog\n",
    "        weight3 = 0.2  # Weight for descriptors orb\n",
    "        weight4 = 0.9  # Weight for descriptors sift\n",
    "            \n",
    "        hog_descriptors = hog_extraction(extracted_face)\n",
    "        try:  \n",
    "            # Calculate the Z-scores for each descriptor\n",
    "            zscore_hog_descriptors = (hog_descriptors - np.mean(hog_descriptors)) / np.std(hog_descriptors)\n",
    "            # Fusion using weighted sum\n",
    "            hog_descriptors = weight2 * zscore_hog_descriptors   \n",
    "        except Exception as e:\n",
    "            # print(str(e), np.std(hog_descriptors))\n",
    "            pass    \n",
    "        hog_descriptors = np.resize(hog_descriptors, (desired_length,))\n",
    "\n",
    "        lbp_descriptors = lbp_extraction(extracted_face)\n",
    "        # Calculate the Z-scores for each descriptor\n",
    "        zscore_lbp_descriptors = (lbp_descriptors - np.mean(lbp_descriptors)) / np.std(lbp_descriptors)\n",
    "        # Fusion using weighted sum\n",
    "        lbp_descriptors = weight1 * zscore_lbp_descriptors \n",
    "        lbp_descriptors = np.resize(lbp_descriptors, (desired_length,))\n",
    "\n",
    "        orb_descriptors = orb_extraction(extracted_face)\n",
    "        # Calculate the Z-scores for each descriptor\n",
    "        # print(\" >>>\", np.std(orb_descriptors))\n",
    "        # print(\" <  > \", orb_descriptors - np.mean(orb_descriptors) )\n",
    "        try:\n",
    "            zscore_orb_descriptors = (orb_descriptors - np.mean(orb_descriptors)) / np.std(orb_descriptors)\n",
    "            # Fusion using weighted sum\n",
    "            orb_descriptors = weight3 * zscore_orb_descriptors \n",
    "            # print(\"orb_descriptors \", orb_descriptors)\n",
    "        except Exception as e:\n",
    "            # print(str(e))\n",
    "            pass\n",
    "        orb_descriptors = np.resize(orb_descriptors, (desired_length,))\n",
    "\n",
    "        sift_descriptors = sift_extraction(extracted_face)\n",
    "        try:\n",
    "            # Calculate the Z-scores for each descriptor\n",
    "            zscore_sift_descriptors = (sift_descriptors - np.mean(sift_descriptors)) / np.std(sift_descriptors)\n",
    "            # Fusion using weighted sum\n",
    "            sift_descriptors = weight4 * zscore_sift_descriptors   \n",
    "        except Exception as e:\n",
    "            # print(str(e))\n",
    "            pass    \n",
    "        sift_descriptors = np.resize(sift_descriptors, (desired_length,))\n",
    "\n",
    "        # fused_features = lbp_descriptors + hog_descriptors + sift_descriptors\n",
    "        fused_features = hog_descriptors\n",
    "        if lbp_descriptors is not None:\n",
    "            fused_features += lbp_descriptors\n",
    "        if sift_descriptors is not None:\n",
    "            fused_features += sift_descriptors.astype(np.float64)\n",
    "\n",
    "        # fused_features = np.concatenate((hog_descriptors, lbp_descriptors, sift_descriptors))\n",
    "\n",
    "        if len(fused_features) > 0:\n",
    "            feature_list.append(fused_features)\n",
    "            label_list.append(image_label)  # Add the label to the list\n",
    "\n",
    "    return feature_list, label_list\n",
    "\n",
    "        # print(fused_features)\n",
    "        \n",
    "        # Display the extracted faces\n",
    "        # cv2.imshow(\"Landmark localization\", extracted_face)\n",
    "        # plt.imshow(pixels)\n",
    "        # plt.axis('off')\n",
    "        # plt.show()\n",
    "\n",
    "def hog_extraction(extracted_face):\n",
    "    # Convert the image to grayscale\n",
    "    image_gray = cv2.cvtColor(extracted_face, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Define HOG parameters\n",
    "    orientations = 9  # Number of gradient orientations\n",
    "    pixels_per_cell = (8, 8)  # Cell size in pixels\n",
    "    cells_per_block = (2, 2)  # Number of cells in each block\n",
    "\n",
    "    # Compute HOG features\n",
    "    hog_image, hog_features = hog(image_gray, orientations=orientations, pixels_per_cell=pixels_per_cell, cells_per_block=cells_per_block, visualize=True)    \n",
    "    # print(hog_features)\n",
    "    disply_feature(\"HOG\", hog_features)\n",
    "    return hog_features\n",
    "\n",
    "def lbp_extraction(extracted_face):\n",
    "    # Compute LBP features\n",
    "\n",
    "    # Get the dimensions of the image\n",
    "    # height, width, channels = extracted_face.shape\n",
    "\n",
    "    # Compute LBP features\n",
    "    radius = 3\n",
    "    n_points = 8 * radius\n",
    "    # convert to 2 dimentional\n",
    "    extracted_face = cv2.cvtColor(extracted_face, cv2.COLOR_BGR2GRAY)\n",
    "    lbp_features = local_binary_pattern(extracted_face, n_points, radius, method='default')\n",
    "    # print(lbp_features)\n",
    "    disply_feature(\"LBP\", lbp_features)\n",
    "    return lbp_features\n",
    "\n",
    "# Scale-Invariant Feature Transform descriptor\n",
    "def sift_extraction(extracted_face):\n",
    "    # Create a SIFT object\n",
    "    sift = cv2.SIFT_create()\n",
    "    # Detect keypoints and compute descriptors\n",
    "    keypoints, descriptors = sift.detectAndCompute(extracted_face, None)\n",
    "    # Draw keypoints on the image\n",
    "    image_with_keypoints = cv2.drawKeypoints(extracted_face, keypoints, None)\n",
    "    # print(descriptors)\n",
    "    disply_feature(\"SIFT\", image_with_keypoints)\n",
    "    return descriptors\n",
    "\n",
    "def orb_extraction(extracted_face):\n",
    "    # Create an ORB object with custom parameters\n",
    "    orb = cv2.ORB_create(nfeatures=1000, scaleFactor=1.2, nlevels=8, edgeThreshold=15)\n",
    "    # Resize the extracted face to a larger size for better feature extraction\n",
    "    extracted_face = cv2.resize(extracted_face, (250, 250))\n",
    "    # Convert the face image to grayscale\n",
    "    extracted_face = cv2.cvtColor(extracted_face, cv2.COLOR_BGR2GRAY)\n",
    "    # Detect keypoints and compute descriptors\n",
    "    keypoints, descriptors = orb.detectAndCompute(extracted_face, None)\n",
    "    # Draw keypoints on the image\n",
    "    image_with_keypoints = cv2.drawKeypoints(extracted_face, keypoints, None, (0, 255, 0), cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "    # disply_feature(\"ORB\", image_with_keypoints)\n",
    "    return descriptors\n",
    "\n",
    "def disply_feature(features_type, features):\n",
    "    # cv2.imshow(features_type, features)\n",
    "    # # plt.imshow( features)\n",
    "    # plt.axis('off')\n",
    "    # plt.show()\n",
    "    pass\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "def svmc(fused_features, img_labels, source_data_label):\n",
    "    \n",
    "    # Create arrays to store the features and labels\n",
    "    fused_features = np.array(fused_features)\n",
    "    img_labels = np.array(img_labels)\n",
    "    \n",
    "    # Reshape the fused features to have two dimensions\n",
    "    # fused_features = fused_features.reshape(-1, fused_features.shape[2])\n",
    "    fused_features = fused_features.reshape(fused_features.shape[0], -1)\n",
    " \n",
    "    # Normalize the feature vectors\n",
    "    scaler = StandardScaler()\n",
    "    fused_features = scaler.fit_transform(fused_features)\n",
    "\n",
    "    # Handle missing values with an imputer transformer\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    fused_features = imputer.fit_transform(fused_features)\n",
    "\n",
    "    # Split the fused features data into training and testing sets\n",
    "    # X_train, X_test, y_train, y_test = train_test_split(fused_features, img_labels, test_size=0.2, random_state=41)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(fused_features, img_labels, test_size=0.002, random_state=41)\n",
    "\n",
    "    # Create an SVM classifier\n",
    "    # instantiate classifier with linear kernel and C=100\n",
    "    svc = svm.SVC(kernel='linear', C=100)\n",
    "\n",
    "    # Train the classifier\n",
    "    svc.fit(X_train, y_train)\n",
    "\n",
    "    # Predict labels for the test set\n",
    "    y_pred = svc.predict(X_test)\n",
    "    # print(y_pred)\n",
    "    # print(\"< ---------------- >\")\n",
    "    # print(y_test)\n",
    "    # print(\"< ---------------- >\")\n",
    "    # print(X_train)\n",
    "    # print(\"< ---------------- >\")\n",
    "    # print(X_test)\n",
    "\n",
    "    # Evaluate the classifier's performance\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='macro', zero_division=1)\n",
    "    recall = recall_score(y_test, y_pred, average='macro', zero_division=1)\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    print(\" 3_without_orb_algo algorithm \", source_data_label)\n",
    "    # Print the evaluation metrics\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F1 Score:\", f1)\n",
    "\n",
    "   \n",
    "    joblib.dump(svc, f\"3_train_without_orb_algo_zscore_on_svm_classifier_{source_data_label}.joblib\")\n",
    "    # joblib.dump(svc, f\"lbp_zscore_on_svm_classifier_{source_data_label}.joblib\")\n",
    "    # joblib.dump(svc, f\"hog_on_svm_classifier_{source_data_label}.joblib\")\n",
    "    # joblib.dump(svc, f\"sift_on_svm_classifier_{source_data_label}.joblib\")\n",
    "\n",
    "file_looper_transformer_extract_features_and_train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa329a0-c845-40ba-a70e-20ecf5fbe83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "  3_without_orb_algo algorithm  jaffedtrain\n",
    "Accuracy: 0.6666666666666666\n",
    "Precision: 0.6666666666666666\n",
    "Recall: 0.8333333333333334\n",
    "F1 Score: 0.5555555555555555"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
